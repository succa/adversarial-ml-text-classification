{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from IPython.display import HTML as html_print\n",
    "\n",
    "import spacy\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic Analysis\n",
    "ms_E3_H1   = pd.read_csv('./data/results/both/ms_3_1_timeout.csv')\n",
    "ms_E3_H2   = pd.read_csv('./data/results/both/ms_3_2_timeout.csv')\n",
    "ms_E3_H5   = pd.read_csv('./data/results/both/ms_3_5_timeout.csv')\n",
    "ms_E3_H10  = pd.read_csv('./data/results/both/ms_3_10_timeout.csv')\n",
    "ms_E3_H100 = pd.read_csv('./data/results/both/ms_3_100_timeout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>doc</th>\n",
       "      <th>adv</th>\n",
       "      <th>success</th>\n",
       "      <th>confidence</th>\n",
       "      <th>adv_confidence</th>\n",
       "      <th>cost</th>\n",
       "      <th>changes</th>\n",
       "      <th>indexes</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@ellcol Haha. I do wonder what some people thi...</td>\n",
       "      <td>@ellcol Haha . I do wonder what some people th...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990256</td>\n",
       "      <td>0.491886</td>\n",
       "      <td>6.583245</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[30, 31]</td>\n",
       "      <td>160.891344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I'll say it again, just eat REAL food! Limit r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@ShepNewsTeam why do you always give find the ...</td>\n",
       "      <td>@ShepNewsTeam why do you always give find the ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.380889</td>\n",
       "      <td>0.544787</td>\n",
       "      <td>0.931648</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[54]</td>\n",
       "      <td>2.935118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Still have a tiny amount of Australian super s...</td>\n",
       "      <td>Still have a tiny amount of Australian supper ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.986061</td>\n",
       "      <td>0.400522</td>\n",
       "      <td>6.678385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[17, 9, 7, 37]</td>\n",
       "      <td>510.443077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"I hate The Weeknd.\"\\nAnd in that moment, the ...</td>\n",
       "      <td>\" I hate The Weeknd . \" \\n And in that moment ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.412468</td>\n",
       "      <td>0.572751</td>\n",
       "      <td>0.934812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[29]</td>\n",
       "      <td>2.043660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>@Garge0 @TrYHARD_CupCAkE i know lol the earlie...</td>\n",
       "      <td>@Garge0 @TrYHARD_CupCAkE i know lol the earlie...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.819217</td>\n",
       "      <td>0.399570</td>\n",
       "      <td>2.719425</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[20, 18]</td>\n",
       "      <td>30.256414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>My thought on the information singularity: giv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>I just bought tickets for Post War Glamour Gir...</td>\n",
       "      <td>I just bought tickets for Post War Glamour Gir...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.322794</td>\n",
       "      <td>0.535360</td>\n",
       "      <td>1.306044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[22]</td>\n",
       "      <td>2.474686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>Soooo... where should Travis and I book a room...</td>\n",
       "      <td>Soooo ... where should Travis and I boko a roo...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.024247</td>\n",
       "      <td>0.535452</td>\n",
       "      <td>7.251725</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[22, 33, 7, 13]</td>\n",
       "      <td>145.412748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>where is fighting all the fucking time gonna g...</td>\n",
       "      <td>where is fighting all the fucking timr gon na ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.159550</td>\n",
       "      <td>0.583794</td>\n",
       "      <td>2.922331</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[29, 6]</td>\n",
       "      <td>13.047664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>I hate not living next to and down the hill fr...</td>\n",
       "      <td>I hate not living next to and down the hill fr...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.133802</td>\n",
       "      <td>0.541729</td>\n",
       "      <td>2.864536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[10]</td>\n",
       "      <td>16.894822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>Curled up with my head on your chest it's the ...</td>\n",
       "      <td>Curled up with my head on your chest it 's the...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.195888</td>\n",
       "      <td>0.578519</td>\n",
       "      <td>2.495769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[29]</td>\n",
       "      <td>51.201873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19</td>\n",
       "      <td>A piece of exciting news: We are now taking pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>Why everyone always hate their ex? Likeyeah i ...</td>\n",
       "      <td>Why everyone always hate their ex ? Likeyeah i...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.210541</td>\n",
       "      <td>0.503930</td>\n",
       "      <td>1.984758</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[27, 24]</td>\n",
       "      <td>108.524766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21</td>\n",
       "      <td>I own a good majority of RVCA men's sized larg...</td>\n",
       "      <td>I own a good majority of RVCA men 's sied lagr...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.356175</td>\n",
       "      <td>0.511485</td>\n",
       "      <td>0.929199</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[10, 9]</td>\n",
       "      <td>5.923558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22</td>\n",
       "      <td>@Spandavia @SMEAllianceLtd With Employers cont...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23</td>\n",
       "      <td>My nan and grandad sent me 10 physical British...</td>\n",
       "      <td>My nan and grandad sent me 10 physical Britsh ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.132169</td>\n",
       "      <td>0.524003</td>\n",
       "      <td>2.791772</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[8, 9]</td>\n",
       "      <td>101.689092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24</td>\n",
       "      <td>Look who I just saw on the TV @Clencha https:/...</td>\n",
       "      <td>Look who I just saw on the TV @Clencha https:/...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.702059</td>\n",
       "      <td>0.396908</td>\n",
       "      <td>1.796161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[28]</td>\n",
       "      <td>0.711348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>college loan holder blow up your reps. email a...</td>\n",
       "      <td>college loan holder blow up your resp . email ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.306380</td>\n",
       "      <td>0.500990</td>\n",
       "      <td>1.180179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[6]</td>\n",
       "      <td>38.682857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26</td>\n",
       "      <td>Stanford opened at 11 and is now a 13 point fa...</td>\n",
       "      <td>Stanford opened at 11 and is now a 13 pointedn...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.957336</td>\n",
       "      <td>0.471021</td>\n",
       "      <td>4.932594</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[10, 9]</td>\n",
       "      <td>20.702149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27</td>\n",
       "      <td>My painting teacher told us all to take a 10 m...</td>\n",
       "      <td>My painting teacher told us all to take a 10 m...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.081636</td>\n",
       "      <td>0.580273</td>\n",
       "      <td>3.962926</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[28, 31]</td>\n",
       "      <td>37.171348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>28</td>\n",
       "      <td>Savana literally watched a rock come and hit m...</td>\n",
       "      <td>Savana literally watched a rock come and hit m...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.294297</td>\n",
       "      <td>0.510975</td>\n",
       "      <td>1.462764</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[20, 15, 9, 11]</td>\n",
       "      <td>68.788822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29</td>\n",
       "      <td>I don't put myself in the best situations | go...</td>\n",
       "      <td>I do n't put myself in the best situations | g...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.362191</td>\n",
       "      <td>0.530401</td>\n",
       "      <td>0.958502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[11]</td>\n",
       "      <td>5.390012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>31</td>\n",
       "      <td>Here are some potential #taxfreesavingsaccount...</td>\n",
       "      <td>Here are some potential # taxfreesavingsaccoun...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.766105</td>\n",
       "      <td>0.472467</td>\n",
       "      <td>1.811490</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[27, 28]</td>\n",
       "      <td>9.115751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>I miss going to prentiss every holiday and sum...</td>\n",
       "      <td>I miss going to prentiss every holiday and sum...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.053159</td>\n",
       "      <td>0.610980</td>\n",
       "      <td>4.753430</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[23, 24]</td>\n",
       "      <td>377.832349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>33</td>\n",
       "      <td>Look forward to driving up to Mt. Airy to watc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>36</td>\n",
       "      <td>Of course when I wanna go home on the quicknes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>37</td>\n",
       "      <td>Gtfo of the bathroom and fucking make your cal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>38</td>\n",
       "      <td>@awesomeknight69 I had a friend watch it with ...</td>\n",
       "      <td>@awesomeknight69 I had a friend watch it with ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.312752</td>\n",
       "      <td>0.604943</td>\n",
       "      <td>1.761064</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[44, 12]</td>\n",
       "      <td>26.166700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>39</td>\n",
       "      <td>the junior doctors had civil unrest in london ...</td>\n",
       "      <td>the juniοr doctors had civil unrest in london ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.869208</td>\n",
       "      <td>0.479239</td>\n",
       "      <td>2.800388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[1, 9]</td>\n",
       "      <td>32.406396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>63</td>\n",
       "      <td>@snitchwich they'll probably count it as a no ...</td>\n",
       "      <td>@snitchwich they 'll probably count it as a no...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.312275</td>\n",
       "      <td>0.583546</td>\n",
       "      <td>1.585485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>2.686140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>64</td>\n",
       "      <td>The Rise Of The Smartphone Means The End Of Mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>65</td>\n",
       "      <td>Then makes the same video on his main channel ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>66</td>\n",
       "      <td>Ion know what I wanna eat forreal . I want ric...</td>\n",
       "      <td>Ion know what I wanna eat forreal . I want ric...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.078954</td>\n",
       "      <td>0.554749</td>\n",
       "      <td>3.766599</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[22, 18]</td>\n",
       "      <td>49.632670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>67</td>\n",
       "      <td>\"TMZ: Former Wizards SF Rice Jr. Shot in the L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.917302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>194.219151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>68</td>\n",
       "      <td>@CoqBlocker shit yeah thats very true, will do...</td>\n",
       "      <td>@CoqBlocker shit yeah that s very true , will ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.971125</td>\n",
       "      <td>0.495284</td>\n",
       "      <td>4.989396</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[11, 29, 26, 30]</td>\n",
       "      <td>391.311314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>69</td>\n",
       "      <td>All i want to do is travel the world | long is...</td>\n",
       "      <td>All i want to do is travel the world | long is...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.157430</td>\n",
       "      <td>0.579425</td>\n",
       "      <td>2.879263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[13]</td>\n",
       "      <td>0.839694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>70</td>\n",
       "      <td>@ChowYaDoin @jenawatkins Is the Her Diamonds v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>71</td>\n",
       "      <td>Plot twist... When you accidentally find out o...</td>\n",
       "      <td>Plot twist ... When you accidentally find out ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.102405</td>\n",
       "      <td>0.624905</td>\n",
       "      <td>3.864638</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[14]</td>\n",
       "      <td>9.459402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>72</td>\n",
       "      <td>@angee_moinette oh yeah !!!! And he still has ...</td>\n",
       "      <td>@angee_moinette oh yeah ! ! ! ! And he still h...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.184511</td>\n",
       "      <td>0.505878</td>\n",
       "      <td>2.929449</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[37, 34, 33]</td>\n",
       "      <td>512.442472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>73</td>\n",
       "      <td>AND WHAT MAKES IT EVEN WORSE is that this Targ...</td>\n",
       "      <td>AND WHAT MAKES IT EVEN WORSE is that this Targ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.041736</td>\n",
       "      <td>0.503821</td>\n",
       "      <td>4.829931</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[19, 43, 32, 20]</td>\n",
       "      <td>98.215385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>74</td>\n",
       "      <td>The Halloween 2 remake is so stupid. As well a...</td>\n",
       "      <td>The Halloween 2 remak is so stupid . As well a...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.953054</td>\n",
       "      <td>0.369045</td>\n",
       "      <td>4.995964</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[16, 3, 24]</td>\n",
       "      <td>22.067132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>75</td>\n",
       "      <td>Can't wait till I have a house, career and fam...</td>\n",
       "      <td>Ca n't wait till I have a house , career and d...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.320491</td>\n",
       "      <td>0.508687</td>\n",
       "      <td>1.109290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[11]</td>\n",
       "      <td>7.363467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>76</td>\n",
       "      <td>@briitstyles the struggle of this drama _Ù÷_ |...</td>\n",
       "      <td>@briitstyles the struggle of this drams _ Ù÷ _...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.278558</td>\n",
       "      <td>0.526417</td>\n",
       "      <td>1.529678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[5]</td>\n",
       "      <td>9.966620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>77</td>\n",
       "      <td>The POLITICS of evidence + results in internat...</td>\n",
       "      <td>The POLITICS of evidence + results in internat...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.469436</td>\n",
       "      <td>3.719686</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[27, 22]</td>\n",
       "      <td>6.380670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>78</td>\n",
       "      <td>Doods are public universities in the US comple...</td>\n",
       "      <td>Doods are public universities in the U.S. comp...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.226706</td>\n",
       "      <td>0.522971</td>\n",
       "      <td>1.878380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[6]</td>\n",
       "      <td>9.629479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>79</td>\n",
       "      <td>The other day, I tried to come up w/ a curse w...</td>\n",
       "      <td>The other day , I tried to come up w/ a curse ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.086344</td>\n",
       "      <td>0.608226</td>\n",
       "      <td>3.914204</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[17]</td>\n",
       "      <td>15.034996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>81</td>\n",
       "      <td>@johncanzanobft just do the math yourselves if...</td>\n",
       "      <td>@johncanzanobft just do the math yourselves if...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.993837</td>\n",
       "      <td>0.467162</td>\n",
       "      <td>7.417699</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[27, 29]</td>\n",
       "      <td>21.245043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>83</td>\n",
       "      <td>@LucyYaOfficial make most of it and drink heap...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>85</td>\n",
       "      <td>The realist person I know, my boy #jr. I'm gon...</td>\n",
       "      <td>The realist person I know , my boy # jr . I 'm...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.544325</td>\n",
       "      <td>0.420234</td>\n",
       "      <td>0.953955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[17]</td>\n",
       "      <td>3.036350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>87</td>\n",
       "      <td>@WhitneyLaVictor we didn't even get to watch i...</td>\n",
       "      <td>@WhitneyLaVictor we did n't even get to watch ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.099919</td>\n",
       "      <td>0.564565</td>\n",
       "      <td>3.576673</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[25, 27]</td>\n",
       "      <td>63.077729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>88</td>\n",
       "      <td>I literally Hoover it and then do this omg  ht...</td>\n",
       "      <td>I literally Hoover it and then do this omg    ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.092296</td>\n",
       "      <td>0.539809</td>\n",
       "      <td>3.675344</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[17, 18]</td>\n",
       "      <td>28.678113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>89</td>\n",
       "      <td>Just trying to go home and sleep | I can get y...</td>\n",
       "      <td>Just trying to go home and sleep | I can incur...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.586751</td>\n",
       "      <td>0.477757</td>\n",
       "      <td>0.621333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[10]</td>\n",
       "      <td>14.378901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>90</td>\n",
       "      <td>They started 5 weeks apart and both got promot...</td>\n",
       "      <td>They started 5 weeks apart and both got promot...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.100268</td>\n",
       "      <td>0.522893</td>\n",
       "      <td>3.504600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[21, 17, 13]</td>\n",
       "      <td>233.176481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>92</td>\n",
       "      <td>Digging Deep Reveals the Intricate World of Ro...</td>\n",
       "      <td>Digging Deep Reveals the Іntricate orld of Foo...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.746132</td>\n",
       "      <td>0.456798</td>\n",
       "      <td>1.825742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[5, 7, 4]</td>\n",
       "      <td>20.648313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>93</td>\n",
       "      <td>@_kittyL when? I'm off Friday and Saturday _Ù÷...</td>\n",
       "      <td>@_kittyL when ? I ' m Frіday Friday and Saturd...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.247144</td>\n",
       "      <td>0.500596</td>\n",
       "      <td>1.562559</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[15, 6]</td>\n",
       "      <td>10.530455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>94</td>\n",
       "      <td>I'm not rockin with the spiders that decide to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>95</td>\n",
       "      <td>#Steelers CB Brandon Boykin ready to prove he ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>96</td>\n",
       "      <td>I can't hold back i gotta live life...go and g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.541766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>583.147302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>98</td>\n",
       "      <td>American horror story and chill?? | my adventu...</td>\n",
       "      <td>American horror history and chill ? ? | my adv...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.132310</td>\n",
       "      <td>0.509121</td>\n",
       "      <td>2.749267</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[2, 11]</td>\n",
       "      <td>82.345703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                                doc  \\\n",
       "0       1  @ellcol Haha. I do wonder what some people thi...   \n",
       "1       2  I'll say it again, just eat REAL food! Limit r...   \n",
       "2       3  @ShepNewsTeam why do you always give find the ...   \n",
       "3       4  Still have a tiny amount of Australian super s...   \n",
       "4       5  \"I hate The Weeknd.\"\\nAnd in that moment, the ...   \n",
       "5       9  @Garge0 @TrYHARD_CupCAkE i know lol the earlie...   \n",
       "6      10  My thought on the information singularity: giv...   \n",
       "7      12  I just bought tickets for Post War Glamour Gir...   \n",
       "8      13  Soooo... where should Travis and I book a room...   \n",
       "9      14  where is fighting all the fucking time gonna g...   \n",
       "10     15  I hate not living next to and down the hill fr...   \n",
       "11     16  Curled up with my head on your chest it's the ...   \n",
       "12     19  A piece of exciting news: We are now taking pr...   \n",
       "13     20  Why everyone always hate their ex? Likeyeah i ...   \n",
       "14     21  I own a good majority of RVCA men's sized larg...   \n",
       "15     22  @Spandavia @SMEAllianceLtd With Employers cont...   \n",
       "16     23  My nan and grandad sent me 10 physical British...   \n",
       "17     24  Look who I just saw on the TV @Clencha https:/...   \n",
       "18     25  college loan holder blow up your reps. email a...   \n",
       "19     26  Stanford opened at 11 and is now a 13 point fa...   \n",
       "20     27  My painting teacher told us all to take a 10 m...   \n",
       "21     28  Savana literally watched a rock come and hit m...   \n",
       "22     29  I don't put myself in the best situations | go...   \n",
       "23     31  Here are some potential #taxfreesavingsaccount...   \n",
       "24     32  I miss going to prentiss every holiday and sum...   \n",
       "25     33  Look forward to driving up to Mt. Airy to watc...   \n",
       "26     36  Of course when I wanna go home on the quicknes...   \n",
       "27     37  Gtfo of the bathroom and fucking make your cal...   \n",
       "28     38  @awesomeknight69 I had a friend watch it with ...   \n",
       "29     39  the junior doctors had civil unrest in london ...   \n",
       "..    ...                                                ...   \n",
       "47     63  @snitchwich they'll probably count it as a no ...   \n",
       "48     64  The Rise Of The Smartphone Means The End Of Mo...   \n",
       "49     65  Then makes the same video on his main channel ...   \n",
       "50     66  Ion know what I wanna eat forreal . I want ric...   \n",
       "51     67  \"TMZ: Former Wizards SF Rice Jr. Shot in the L...   \n",
       "52     68  @CoqBlocker shit yeah thats very true, will do...   \n",
       "53     69  All i want to do is travel the world | long is...   \n",
       "54     70  @ChowYaDoin @jenawatkins Is the Her Diamonds v...   \n",
       "55     71  Plot twist... When you accidentally find out o...   \n",
       "56     72  @angee_moinette oh yeah !!!! And he still has ...   \n",
       "57     73  AND WHAT MAKES IT EVEN WORSE is that this Targ...   \n",
       "58     74  The Halloween 2 remake is so stupid. As well a...   \n",
       "59     75  Can't wait till I have a house, career and fam...   \n",
       "60     76  @briitstyles the struggle of this drama _Ù÷_ |...   \n",
       "61     77  The POLITICS of evidence + results in internat...   \n",
       "62     78  Doods are public universities in the US comple...   \n",
       "63     79  The other day, I tried to come up w/ a curse w...   \n",
       "64     81  @johncanzanobft just do the math yourselves if...   \n",
       "65     83  @LucyYaOfficial make most of it and drink heap...   \n",
       "66     85  The realist person I know, my boy #jr. I'm gon...   \n",
       "67     87  @WhitneyLaVictor we didn't even get to watch i...   \n",
       "68     88  I literally Hoover it and then do this omg  ht...   \n",
       "69     89  Just trying to go home and sleep | I can get y...   \n",
       "70     90  They started 5 weeks apart and both got promot...   \n",
       "71     92  Digging Deep Reveals the Intricate World of Ro...   \n",
       "72     93  @_kittyL when? I'm off Friday and Saturday _Ù÷...   \n",
       "73     94  I'm not rockin with the spiders that decide to...   \n",
       "74     95  #Steelers CB Brandon Boykin ready to prove he ...   \n",
       "75     96  I can't hold back i gotta live life...go and g...   \n",
       "76     98  American horror story and chill?? | my adventu...   \n",
       "\n",
       "                                                  adv success  confidence  \\\n",
       "0   @ellcol Haha . I do wonder what some people th...    True    0.990256   \n",
       "1                                                 NaN   False         NaN   \n",
       "2   @ShepNewsTeam why do you always give find the ...    True    0.380889   \n",
       "3   Still have a tiny amount of Australian supper ...    True    0.986061   \n",
       "4   \" I hate The Weeknd . \" \\n And in that moment ...    True    0.412468   \n",
       "5   @Garge0 @TrYHARD_CupCAkE i know lol the earlie...    True    0.819217   \n",
       "6                                                 NaN   False         NaN   \n",
       "7   I just bought tickets for Post War Glamour Gir...    True    0.322794   \n",
       "8   Soooo ... where should Travis and I boko a roo...    True    0.024247   \n",
       "9   where is fighting all the fucking timr gon na ...    True    0.159550   \n",
       "10  I hate not living next to and down the hill fr...    True    0.133802   \n",
       "11  Curled up with my head on your chest it 's the...    True    0.195888   \n",
       "12                                                NaN   False         NaN   \n",
       "13  Why everyone always hate their ex ? Likeyeah i...    True    0.210541   \n",
       "14  I own a good majority of RVCA men 's sied lagr...    True    0.356175   \n",
       "15                                                NaN   False         NaN   \n",
       "16  My nan and grandad sent me 10 physical Britsh ...    True    0.132169   \n",
       "17  Look who I just saw on the TV @Clencha https:/...    True    0.702059   \n",
       "18  college loan holder blow up your resp . email ...    True    0.306380   \n",
       "19  Stanford opened at 11 and is now a 13 pointedn...    True    0.957336   \n",
       "20  My painting teacher told us all to take a 10 m...    True    0.081636   \n",
       "21  Savana literally watched a rock come and hit m...    True    0.294297   \n",
       "22  I do n't put myself in the best situations | g...    True    0.362191   \n",
       "23  Here are some potential # taxfreesavingsaccoun...    True    0.766105   \n",
       "24  I miss going to prentiss every holiday and sum...    True    0.053159   \n",
       "25                                                NaN   False         NaN   \n",
       "26                                                NaN   False         NaN   \n",
       "27                                                NaN   False         NaN   \n",
       "28  @awesomeknight69 I had a friend watch it with ...    True    0.312752   \n",
       "29  the juniοr doctors had civil unrest in london ...    True    0.869208   \n",
       "..                                                ...     ...         ...   \n",
       "47  @snitchwich they 'll probably count it as a no...    True    0.312275   \n",
       "48                                                NaN   False         NaN   \n",
       "49                                                NaN   False         NaN   \n",
       "50  Ion know what I wanna eat forreal . I want ric...    True    0.078954   \n",
       "51                                                NaN   False    0.917302   \n",
       "52  @CoqBlocker shit yeah that s very true , will ...    True    0.971125   \n",
       "53  All i want to do is travel the world | long is...    True    0.157430   \n",
       "54                                                NaN   False         NaN   \n",
       "55  Plot twist ... When you accidentally find out ...    True    0.102405   \n",
       "56  @angee_moinette oh yeah ! ! ! ! And he still h...    True    0.184511   \n",
       "57  AND WHAT MAKES IT EVEN WORSE is that this Targ...    True    0.041736   \n",
       "58  The Halloween 2 remak is so stupid . As well a...    True    0.953054   \n",
       "59  Ca n't wait till I have a house , career and d...    True    0.320491   \n",
       "60  @briitstyles the struggle of this drams _ Ù÷ _...    True    0.278558   \n",
       "61  The POLITICS of evidence + results in internat...    True    0.922280   \n",
       "62  Doods are public universities in the U.S. comp...    True    0.226706   \n",
       "63  The other day , I tried to come up w/ a curse ...    True    0.086344   \n",
       "64  @johncanzanobft just do the math yourselves if...    True    0.993837   \n",
       "65                                                NaN   False         NaN   \n",
       "66  The realist person I know , my boy # jr . I 'm...    True    0.544325   \n",
       "67  @WhitneyLaVictor we did n't even get to watch ...    True    0.099919   \n",
       "68  I literally Hoover it and then do this omg    ...    True    0.092296   \n",
       "69  Just trying to go home and sleep | I can incur...    True    0.586751   \n",
       "70  They started 5 weeks apart and both got promot...    True    0.100268   \n",
       "71  Digging Deep Reveals the Іntricate orld of Foo...    True    0.746132   \n",
       "72  @_kittyL when ? I ' m Frіday Friday and Saturd...    True    0.247144   \n",
       "73                                                NaN   False         NaN   \n",
       "74                                                NaN   False         NaN   \n",
       "75                                                NaN   False    0.541766   \n",
       "76  American horror history and chill ? ? | my adv...    True    0.132310   \n",
       "\n",
       "    adv_confidence      cost  changes           indexes        time  \n",
       "0         0.491886  6.583245      2.0          [30, 31]  160.891344  \n",
       "1              NaN       NaN      NaN               NaN  600.000000  \n",
       "2         0.544787  0.931648      1.0              [54]    2.935118  \n",
       "3         0.400522  6.678385      4.0    [17, 9, 7, 37]  510.443077  \n",
       "4         0.572751  0.934812      1.0              [29]    2.043660  \n",
       "5         0.399570  2.719425      2.0          [20, 18]   30.256414  \n",
       "6              NaN       NaN      NaN               NaN  600.000000  \n",
       "7         0.535360  1.306044      1.0              [22]    2.474686  \n",
       "8         0.535452  7.251725      4.0   [22, 33, 7, 13]  145.412748  \n",
       "9         0.583794  2.922331      2.0           [29, 6]   13.047664  \n",
       "10        0.541729  2.864536      1.0              [10]   16.894822  \n",
       "11        0.578519  2.495769      1.0              [29]   51.201873  \n",
       "12             NaN       NaN      NaN               NaN  600.000000  \n",
       "13        0.503930  1.984758      2.0          [27, 24]  108.524766  \n",
       "14        0.511485  0.929199      2.0           [10, 9]    5.923558  \n",
       "15             NaN       NaN      NaN               NaN  600.000000  \n",
       "16        0.524003  2.791772      2.0            [8, 9]  101.689092  \n",
       "17        0.396908  1.796161      1.0              [28]    0.711348  \n",
       "18        0.500990  1.180179      1.0               [6]   38.682857  \n",
       "19        0.471021  4.932594      2.0           [10, 9]   20.702149  \n",
       "20        0.580273  3.962926      2.0          [28, 31]   37.171348  \n",
       "21        0.510975  1.462764      4.0   [20, 15, 9, 11]   68.788822  \n",
       "22        0.530401  0.958502      1.0              [11]    5.390012  \n",
       "23        0.472467  1.811490      2.0          [27, 28]    9.115751  \n",
       "24        0.610980  4.753430      2.0          [23, 24]  377.832349  \n",
       "25             NaN       NaN      NaN               NaN  600.000000  \n",
       "26             NaN       NaN      NaN               NaN  600.000000  \n",
       "27             NaN       NaN      NaN               NaN  600.000000  \n",
       "28        0.604943  1.761064      2.0          [44, 12]   26.166700  \n",
       "29        0.479239  2.800388      2.0            [1, 9]   32.406396  \n",
       "..             ...       ...      ...               ...         ...  \n",
       "47        0.583546  1.585485      1.0              [32]    2.686140  \n",
       "48             NaN       NaN      NaN               NaN  600.000000  \n",
       "49             NaN       NaN      NaN               NaN  600.000000  \n",
       "50        0.554749  3.766599      2.0          [22, 18]   49.632670  \n",
       "51             NaN       NaN      NaN               NaN  194.219151  \n",
       "52        0.495284  4.989396      4.0  [11, 29, 26, 30]  391.311314  \n",
       "53        0.579425  2.879263      1.0              [13]    0.839694  \n",
       "54             NaN       NaN      NaN               NaN  600.000000  \n",
       "55        0.624905  3.864638      1.0              [14]    9.459402  \n",
       "56        0.505878  2.929449      3.0      [37, 34, 33]  512.442472  \n",
       "57        0.503821  4.829931      4.0  [19, 43, 32, 20]   98.215385  \n",
       "58        0.369045  4.995964      3.0       [16, 3, 24]   22.067132  \n",
       "59        0.508687  1.109290      1.0              [11]    7.363467  \n",
       "60        0.526417  1.529678      1.0               [5]    9.966620  \n",
       "61        0.469436  3.719686      2.0          [27, 22]    6.380670  \n",
       "62        0.522971  1.878380      1.0               [6]    9.629479  \n",
       "63        0.608226  3.914204      1.0              [17]   15.034996  \n",
       "64        0.467162  7.417699      2.0          [27, 29]   21.245043  \n",
       "65             NaN       NaN      NaN               NaN  600.000000  \n",
       "66        0.420234  0.953955      1.0              [17]    3.036350  \n",
       "67        0.564565  3.576673      2.0          [25, 27]   63.077729  \n",
       "68        0.539809  3.675344      2.0          [17, 18]   28.678113  \n",
       "69        0.477757  0.621333      1.0              [10]   14.378901  \n",
       "70        0.522893  3.504600      3.0      [21, 17, 13]  233.176481  \n",
       "71        0.456798  1.825742      3.0         [5, 7, 4]   20.648313  \n",
       "72        0.500596  1.562559      2.0           [15, 6]   10.530455  \n",
       "73             NaN       NaN      NaN               NaN  600.000000  \n",
       "74             NaN       NaN      NaN               NaN  600.000000  \n",
       "75             NaN       NaN      NaN               NaN  583.147302  \n",
       "76        0.509121  2.749267      2.0           [2, 11]   82.345703  \n",
       "\n",
       "[77 rows x 10 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_E3_H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text style=color:black>foo <text style=color:red>abc</text> bar</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def cstr(s, color='black'):\n",
    "    return \"<text style=color:{}>{}</text>\".format(color, s)\n",
    "\n",
    "left, word, right = 'foo' , 'abc' , 'bar'\n",
    "html_print(cstr(' '.join([left, cstr(word, color='red'), right]), color='black') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(text, indexes, color):\n",
    "    text = text.split(' ')\n",
    "    def cstr(s, color='black'):\n",
    "        return \"<text style=color:{}>{}</text>\".format(color, s)\n",
    "\n",
    "#     for i in indexes:\n",
    "#         #return html_print(cstr(' '.join([text[:i], cstr(text[:i], color=color), text[i+1:]]), color='black') )\n",
    "#         return cstr(text[i], color=color) + cstr(text[i+1], color=color)\n",
    "    output = []\n",
    "    for i, word in enumerate(text):\n",
    "        if i in indexes:\n",
    "            output.append(cstr(text[i], color=color))\n",
    "        else:\n",
    "            output.append(cstr(text[i], color='black'))\n",
    "    return html_print(' '.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text style=color:black>The</text> <text style=color:red>cat</text> <text style=color:black>is</text> <text style=color:red>on</text> <text style=color:black>the</text> <text style=color:black>table</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_print('The cat is on the table', [1,3], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in ms_E3_H1.iterrows():\n",
    "    if row['success'] == True:\n",
    "        pretty_print(row['adv'], ast.literal_eval(row['indexes']), 'red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(text, adv, indexes):\n",
    "    print(\"Original Text:    \" + text)\n",
    "    print(\"Adversarial Text: \" + adv)\n",
    "    docText = nlp(text)\n",
    "    docAdv  = nlp(adv)\n",
    "    for i in indexes:\n",
    "        print(\"{} ==> {}\".format(docText[i], docAdv[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:    @ellcol Haha. I do wonder what some people think they're getting. Just go to fucking Dubai already, and leave real people alone. | London-born Saxophonist / Composer living in Stockholm. Worked with some people you've heard of and some you haven't. Likes to cook.\n",
      "Adversarial Text: @ellcol Haha . I do wonder what some people think they 're getting . Just go to fucking Dubai already , and leave real people alone . | London - brn Saxophｏnist / Composer living in Stockholm . Worked with some people you ' ve heard of and some you have n't . Likes to cook .\n",
      "born ==> brn\n",
      "Saxophonist ==> Saxophｏnist\n",
      "\n",
      "Original Text:    @ShepNewsTeam why do you always give find the most redneck peeps to interview in SC /NC. We do have very intelligent people! Interview them. | I live in Sunny Wilmington NC, I'm an Ambassador for the Wilmington Chamber of Commerce. My husband and I also have a second home in the suburbs of Pittsburgh.\n",
      "Adversarial Text: @ShepNewsTeam why do you always give find the most redneck peeps to interview in SC /NC . We do have very intelligent people ! Interview them . | I live in Sunny Wilmington NC , I 'm an Ambassador for the Wilmington Chamber of Commerce . My husband and I also have a second abode in the suburbs of Pittsburgh .\n",
      "home ==> second\n",
      "\n",
      "Original Text:    Still have a tiny amount of Australian super sitting on the other side of the Tasman. Thinking of moving it to Kiwisaver. | I'm a journalist, blogger and editor. Invented the software cover disc. Know how to write about technology, not how to do it.\n",
      "Adversarial Text: Still have a tiny amount of Australian duper sitting along the other side of the Tasman . hinking of moving it to Kiwisaver . | I ' m a journalist , blogger and editor . Invented the blanket cover disc . Know how to write about technology , not how to do it .\n",
      "Thinking ==> hinking\n",
      "on ==> along\n",
      "super ==> duper\n",
      "cover ==> blanket\n",
      "\n",
      "Original Text:    \"I hate The Weeknd.\"\n",
      "And in that moment, the potential friendship fizzled. That's where I draw the line. | [Pretend that there's something interesting here]\n",
      "Adversarial Text: \" I hate The Weeknd . \" \n",
      " And in that moment , the potential friendship fizzled . That 's where I draw the line . | [ Pretend htat there 's something interesting here ]\n",
      "that ==> htat\n",
      "\n",
      "Original Text:    @Garge0 @TrYHARD_CupCAkE i know lol the earliest my connects get them is the friday before release | An actual @WeAreDooMClan member!!\n",
      "Adversarial Text: @Garge0 @TrYHARD_CupCAkE i know lol the earliest my connects get them is the friday before release | An literal @WeAreDooMClan membre ! !\n",
      "member ==> membre\n",
      "actual ==> literal\n",
      "\n",
      "Original Text:    I just bought tickets for Post War Glamour Girls  at The Cookie, Leicester from https://t.co/BP7THGHF37! https://t.co/efU07V6cN3 via @ents24 | sure fine whatever\n",
      "Adversarial Text: I just bought tickets for Post War Glamour Girls   at The Cookie , Leicester from https://t.co/BP7THGHF37 ! https://t.co/efU07V6cN3 via @ents24 | zure fine whatever\n",
      "sure ==> zure\n",
      "\n",
      "Original Text:    Soooo... where should Travis and I book a room downtown. (side note: we're not paying) | Carolina Girl. Southern Belle. Wino. Huntress. 2nd Amendment. Country Music. Concert Junkie. NASCAR. Gamecocks. Engaged - #FallForTheMercers 11.21.15.\n",
      "Adversarial Text: Soooo ... where should Travis and I boko a room downtown . ( xide note : we 're not paying ) | Carｏlina Girl . Southern Belle . Wino . Huntress . 2nd Amеndment . Country Music . Concert Junkie . NASCAR . Gamecocks . Engaged - # FallForTheMercers 11.21.15 .\n",
      "Carolina ==> Carｏlina\n",
      "Amendment ==> Amеndment\n",
      "book ==> boko\n",
      "side ==> xide\n",
      "\n",
      "Original Text:    where is fighting all the fucking time gonna get you in life? no where besides getting called an attention seeker... like just stop lol | #VSquad __ü #SheBelieves EagleCrest 2016. @allispinuzzi Is my Bestfriend _ü #BAMF\n",
      "Adversarial Text: where is fighting all the fucking timr gon na get you in life ? no where besides getting called an attention seeker ... like just stop lol | # ⅤSquad __ü # SheBelieves EagleCrest 2016 . @allispinuzzi Is my Bestfriend _ü # BAMF\n",
      "VSquad ==> ⅤSquad\n",
      "time ==> timr\n",
      "\n",
      "Original Text:    I hate not living next to and down the hill from my 2 best friends _Ù÷_ | snapchat- skyebethan instagram- skye_hopkins\n",
      "Adversarial Text: I hate not living next to and down the hill frok my 2 best friends _ Ù÷ _ | snapchat- skyebethan instagram- skye_hopkins\n",
      "from ==> frok\n",
      "\n",
      "Original Text:    Curled up with my head on your chest it's the best remedy for the pain and the stress | bitches ain't shit and they ain't sayin nothin..\n",
      "Adversarial Text: Curled up with my head on your chest it 's the best remedy for the pain and the stress | bitches ai n't shit and they ai n't sayin nothi ..\n",
      "nothin ==> nothi\n",
      "\n",
      "Original Text:    A piece of exciting news: We are now taking pre-orders for James' latest book, scheduled to be released December... https://t.co/rH7RQiSBKI | Minister and author. (Didn't even need 160 characters, ha!)\n",
      "Adversarial Text: A piece of exciting news : We are now taking pre - orders for Janes ' latet book , scheduled to be released December ... https://t.co/rH7RQiSBKI | Minister and writer . ( Did n't een need 160 characters , ha ! )\n",
      "author ==> writer\n",
      "even ==> een\n",
      "latest ==> latet\n",
      "James ==> Janes\n",
      "\n",
      "Original Text:    Why everyone always hate their ex? Likeyeah i had a boyf and i break with him but we still being friends, he never do anything bad to me so. | ö Û¢Bibiloni#/`ìÛ\n",
      "Monster-Skillet\n",
      "http://t.co/can9MK8t4E\n",
      "Adversarial Text: Why everyone always hate their ex ? Likeyeah i had a boyf and i break with him but we still being friends , he nevet do anything unsound to me so . | ö    Û¢Bibiloni#/`ìÛ \n",
      "  Monster - Skillet \n",
      "  http://t.co/can9MK8t4E\n",
      "bad ==> unsound\n",
      "never ==> nevet\n",
      "\n",
      "Original Text:    I own a good majority of RVCA men's sized large clothing and idc | NO BAD DAYS | IG: maddiebowen | #UNCW19\n",
      "Adversarial Text: I own a good majority of RVCA men 's sied lagre clothing and idc | NO BAD DAYS | IG : maddiebowen | # UNCW19\n",
      "large ==> lagre\n",
      "sized ==> sied\n",
      "\n",
      "Original Text:    @Spandavia @SMEAllianceLtd With Employers contributing 3% employees 5% by 2017. and unless people decide to opt out. | Lover of Good food, fishing, Koi keeper, darts fan in a battle with the banks and their toxic products IRSA & finding a voice with http://t.co/eoMWiadUg8\n",
      "Adversarial Text: @Spandavia @SMEAllianceLtd With Employers contributing 3 % employees 5 % by 2017 . and unless peoplr deicde to opt out . | Lover of Good food , fishing , Koi keeper , darts rooter in a battle with the banis and their toxic products IRSA & finding a voice with http://t.co/eoMWiadUg8\n",
      "people ==> peoplr\n",
      "decide ==> deicde\n",
      "fan ==> rooter\n",
      "banks ==> banis\n",
      "\n",
      "Original Text:    My nan and grandad sent me 10 physical British pounds in the post to France I just can't | 20 and living in Paris. Still coming to terms with being a Wiganer with a St Helens home address\n",
      "Adversarial Text: My nan and grandad sent me 10 physical Britsh ounds in the post to France I just ca n't | 20 and living in Paris . Still coming to terms with being a Wiganer with a St Helens home address\n",
      "British ==> Britsh\n",
      "pounds ==> ounds\n",
      "\n",
      "Original Text:    Look who I just saw on the TV @Clencha https://t.co/8a3yyoAENC | PR, marketing & brand manager for pro athletes, owner of @Sixof1PR. Marketing consultant for various organisations. Once produced music for Disney.\n",
      "Adversarial Text: Look who I just saw on the TV @Clencha https://t.co/8a3yyoAENC | PR , marketing & brand manager for pro athletes , owner of @Sixof1PR . Marketing consultant for diverse organisations . Once produced music for Disney .\n",
      "various ==> diverse\n",
      "\n",
      "Original Text:    college loan holder blow up your reps. email and tell them to lower the interest rate,they wouldn't pay it,you shouldn't have to either | nan\n",
      "Adversarial Text: college loan holder blow up your resp . email and tell them to lower the interest rate , they would n't pay it , you should n't have to either | nan\n",
      "reps ==> resp\n",
      "\n",
      "Original Text:    Stanford opened at 11 and is now a 13 point favorite at WSU | Amazing distinction of having worked at all 3 Seattle sports radio stations.\n",
      "Adversarial Text: Stanford opened at 11 and is now a 13 pointedness pet at WSU | Amazing distinction of having worked at all 3 Seattle sports radio stations .\n",
      "favorite ==> pet\n",
      "point ==> pointedness\n",
      "\n",
      "Original Text:    My painting teacher told us all to take a 10 minute nap and well, we did | ªÁTouhouªÁLove LiveªÁLolitaªÁ I live for cute and I draw the cute. // Header by @nyoki_hado\n",
      "Adversarial Text: My painting teacher told us all to take a 10 minute nap and well , we did | ªÁTouhouªÁLove LiveªÁLolitaªÁ I live for cute and I draw the cite . // Hader by @nyoki_hado\n",
      "cute ==> cite\n",
      "Header ==> Hader\n",
      "\n",
      "Original Text:    Savana literally watched a rock come and hit my windshield and crack it on the freeway _Ù÷â_Ù÷ã_Ù÷ã_Ù÷ã #stupidtrucks @SavanaEspinoza | nan\n",
      "Adversarial Text: Savana literally watched a rock come and hit my windsheild and rack it on the throughway _ Ù÷â_Ù÷ã_Ù÷ã_Ù÷ã # stupidtrucks @SavanaEspｉnoza | nan\n",
      "@SavanaEspinoza ==> @SavanaEspｉnoza\n",
      "freeway ==> throughway\n",
      "windshield ==> windsheild\n",
      "crack ==> rack\n",
      "\n",
      "Original Text:    I don't put myself in the best situations | got dark circles but I still look better than ur bitch\n",
      "Adversarial Text: I do n't put myself in the best situations | got obscure circles but I still look better than ur bitch\n",
      "dark ==> obscure\n",
      "\n",
      "Original Text:    Here are some potential #taxfreesavingsaccounts #TFSA avenues the Liberals could take and #tax changes as too  https://t.co/hTAEBf7ReX | Waterloo Financial Planner with 23 years experience, specializing in Retirement and Estate planning.\n",
      "Adversarial Text: Here are some potential # taxfreesavingsaccounts # TFSA avenues the Liberals could take and # tax changes as too    https://t.co/hTAEBf7ReX | Waterloo Financial Planner with 23 days xperience , specializing in Retirement and Estate planning .\n",
      "years ==> days\n",
      "experience ==> xperience\n",
      "\n",
      "Original Text:    I miss going to prentiss every holiday and summers man.. I miss my childhood and teenage years. | God fearing. Beautiful mind. Huge heart.\n",
      "Adversarial Text: I miss going to prentiss every holiday and summers man .. I miss my childhood and teenage years . | God fearing . Beautifull thinker . Huge heart .\n",
      "Beautiful ==> Beautifull\n",
      "mind ==> thinker\n",
      "\n",
      "Original Text:    Of course when I wanna go home on the quickness it's taken the longest to get there | Cuban, colombian cali girl in RI instagram @adrianadarling\n",
      "Adversarial Text: Of course when I wanna go home on the quickness it 's takken the longest to get thither | Cuba , colombian calk girl in RI instagram @adrianadarling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cali ==> calk\n",
      "Cuban ==> Cuba\n",
      "taken ==> takken\n",
      "there ==> thither\n",
      "\n",
      "Original Text:    Gtfo of the bathroom and fucking make your calls outside you're annoying ÏÜ | Mama tried to raise a lady, but daddy won, he raised a lady who doesn't take shit from anyone. -Miranda Lambert\n",
      "Adversarial Text: Gtfo of the bathroom and fucking make your calls outside you 're annoying ÏÜ | Mama tried to elevate a lady , but daddy won , he raiser a lady who does n't take sshit from amyone . -Miranda Lambert\n",
      "raise ==> elevate\n",
      "raised ==> raiser\n",
      "shit ==> sshit\n",
      "anyone ==> amyone\n",
      "\n",
      "Original Text:    @awesomeknight69 I had a friend watch it with me before. we both watched it over Skype and he actually started liking my little pony. | #Hitler4prez2016 | Instagram: cutiepiefluttershy | Anime/Video Game/Music/Horror Enthusiast | PokÌ©mon Master | MDD FOREVER | Gamertag: MLPonyBondage\n",
      "Adversarial Text: @awesomeknight69 I had a friend watch it with me before . we boh watched it over Skype and he actually started liking my little pony . | # Hitler4prez2016 | Instagram : cutiepiefluttershy | Anime / Video Game / Music / Horror Enthusiast | PoｋÌ © mon Master | MDD FOREVER | Gamertag : MLPonyBondage\n",
      "PokÌ ==> PoｋÌ\n",
      "both ==> boh\n",
      "\n",
      "Original Text:    the junior doctors had civil unrest in london yet hardly reported | nan\n",
      "Adversarial Text: the junⅰor doctors had civil unrest in london yet scarcely reported | nan\n",
      "junior ==> junⅰor\n",
      "hardly ==> scarcely\n",
      "\n",
      "Original Text:    If you are happy I'm happy for you. And that's what love is. | I no longer live in FL. #kobetaughtyou\n",
      "Adversarial Text: If you are happy I 'm happy for you . And that 's what lobe is . | I no longer live in FL . # kobetaughtyou\n",
      "love ==> what\n",
      "\n",
      "Original Text:    Go drive your car in to a spiked wall at 75 mph so your death is painful and disgusting  https://t.co/9l3y9JnliD | IG: jaydenfinesse\n",
      "Adversarial Text: Go drive your car in to a spiked wall at 75 mph so y0ur decease is painful and disgusting    https://t.co/9l3y9JnliD | IG : jaydenfinesse\n",
      "your ==> y0ur\n",
      "death ==> decease\n",
      "\n",
      "Original Text:    camerons side of the bed smells SO bad | I like to sleep\n",
      "Adversarial Text: camerons side of the bed smells SO bad | I loke to slee\n",
      "sleep ==> slee\n",
      "like ==> loke\n",
      "\n",
      "Original Text:    \"What is defeat? Nothing but education; nothing but the first step to something better.\" - Wendell Phillips | All Bible quotations are from the MSG, KJV and Amplified Versions.\n",
      "Adversarial Text: \" What is defeat ? Nothing but education ; nothing but the fisrt step to something better . \" - Wendel Phillips | All Bible quotations are from the MSG , KJV and Amplified Versions .\n",
      "Wendell ==> Wendel\n",
      "first ==> fisrt\n",
      "\n",
      "Original Text:    @yung_flacko_ @SniparsNiall im really sensitive over the internet | 16 | London | put my @ in your suicide note\n",
      "Adversarial Text: @yung_flacko _ @SniparsNiall i m really sensitive ober the interner | 16 | London | put my @ in your suicide note\n",
      "internet ==> interner\n",
      "over ==> ober\n",
      "\n",
      "Original Text:    Can I not go to work, eat pizza and watch the ultimate fighter all day? | Building an Empire\n",
      "Adversarial Text: Can I not go to work , eat pizza and watch the ultimate fighter all day ? | Buillding an Empie\n",
      "Empire ==> Empie\n",
      "Building ==> Buillding\n",
      "\n",
      "Original Text:    I made a pumpkin spice latte and cookies... I have officially out basic-ed myself | Wanna save the world, don't know how...\n",
      "Adversarial Text: I made a pumpkin spiciness latte and cookies ... I have officially out basic - ed myself | Wanna save the world , do n't knos how ...\n",
      "spice ==> spiciness\n",
      "know ==> knos\n",
      "\n",
      "Original Text:    @cedarpoint if you visit four times the extra you would pay for a platinum is covered in free parking. #NoBrainer | Breast cancer awareness advocate, Physical Education instructor at Lakeland Community College with an Ophthalmic Tech degree, and a self proclaimed beach bum.\n",
      "Adversarial Text: @cedarpoint if you visit four times the extra you would pay for a platinum is covered in free parking . # NoBrainer | Breast cancer awareness advocate , Physical Education instrｕctor at Lakeland Community College with an Opthalmic Tech degee , and a self proclaimed beach bum .\n",
      "instructor ==> instrｕctor\n",
      "degree ==> degee\n",
      "Ophthalmic ==> Opthalmic\n",
      "\n",
      "Original Text:    @onedirection Artist of the year #AMAs | nan\n",
      "Adversarial Text: @onedirection Artist of the gear # AMAs | nan\n",
      "year ==> gear\n",
      "\n",
      "Original Text:    The only nudes he'll be getting are the colour schemes for my art | sunsets and adventures\n",
      "Adversarial Text: The only nudes he 'll be getting are the colour schemes for my art | ｓunsets and adventured\n",
      "adventures ==> adventured\n",
      "sunsets ==> ｓunsets\n",
      "\n",
      "Original Text:    Hi @Caspar_Lee  my sisters bday is coming up and it would be great if you could tweet me a little message with her name(Amy Snoeren) in it ªÁ | nan\n",
      "Adversarial Text: Hi @Caspar_Lee     my sisters bday is coming up and it would be great if you could tweet me a small messsage wіth her name(Amy Snoeren ) in it ªÁ | nan\n",
      "little ==> small\n",
      "message ==> messsage\n",
      "with ==> wіth\n",
      "\n",
      "Original Text:    @DeductiveSH \n",
      "*Smile and pet your curls* | He owns me, I own the rest of the world. #ROLE PLAY #NSFW GRAPHIC+18 only.\n",
      "Adversarial Text: @DeductiveSH \n",
      " * Smile and pet your curls * | He owns me , I own the rest of the world . # DOLE PLAY # NSFW GRAPHIC+18 only .\n",
      "ROLE ==> DOLE\n",
      "\n",
      "Original Text:    You came across well on the telly box @tomgreaves85 @FCUnitedMcr | Enjoy watching sports, drinking a few pints and eating all the wrong foods\n",
      "Adversarial Text: You came across well on the telly box @tomgreaves85 @FCUnitedMcr | Enjoy watching sports , drunking a few pints and eating all the wrong foods\n",
      "drinking ==> drunking\n",
      "\n",
      "Original Text:    @btsportrugby ask Jonah about Joost vd Westhasian and the 1995 final. #bravestplayer | nan\n",
      "Adversarial Text: @btsportrugby ask Jonah about Joost vd Westhasian and the 199５ vinal . # bravestplayer | nan\n",
      "1995 ==> 199５\n",
      "final ==> vinal\n",
      "\n",
      "Original Text:    @RockyRoark it doesn't seem to matter since they select what is featured on the site. It all depends on when you promote it via social media | Professional sitter & high-five enthusiast | Designer @ McGarrah Jessee | I have Pop Pop in the attic.\n",
      "Adversarial Text: @RockyRoark it does n't seem to matter since they select what is featured on the site . It all depends on when you promote it via social media | Profｅssional sitter & high - five enthusiast | Designｅr @ McGarrah Jessee | I have Pop Pop in the attic .\n",
      "Professional ==> Profｅssional\n",
      "Designer ==> Designｅr\n",
      "\n",
      "Original Text:    The House science committee is worse than the Benghazi committee https://t.co/vv9laZvYQ9 | I am chair of the LGBT Caucus of the Democratic Party of Hawaii! We have to take a stand to make a difference!\n",
      "Adversarial Text: The House science committee is worse than the Benghazi committee https://t.co/vv9laZvYQ9 | I am chair of the LGBT Caucus of the Democratic Party of Hawaii ! We have to take a stand to make a conflict !\n",
      "difference ==> conflict\n",
      "\n",
      "Original Text:    @snitchwich they'll probably count it as a no show and either fire you or put you one step closer to being fired, that's how all my jobs | foxy grandpa\n",
      "Adversarial Text: @snitchwich they 'll probably count it as a no show and either fire you or put you one step closer to being fired , that 's how all my jobs | foxy grandfather\n",
      "grandpa ==> grandfather\n",
      "\n",
      "Original Text:    The Rise Of The Smartphone Means The End Of Mobile Wallets From Carriers And Banks: https://t.co/WDIVV5DqLK | I can has Social Media\n",
      "Adversarial Text: The Rise Of The Smartphone Means The End Of Mobile Wallet Fromm Carriers And Banks : https://t.co/WDIVV5DqLK | I can has Socal Meria\n",
      "Media ==> Meria\n",
      "Social ==> Socal\n",
      "From ==> Fromm\n",
      "Wallets ==> Wallet\n",
      "\n",
      "Original Text:    Ion know what I wanna eat forreal . I want rice but I'm tired of donnas and mall food | Breon here\n",
      "Adversarial Text: Ion know what I wanna eat forreal . I want rice but I ' m tired of donnas center mall food | Breon hefe\n",
      "here ==> Breon\n",
      "mall ==> center\n",
      "\n",
      "Original Text:    @CoqBlocker shit yeah thats very true, will do when im back in england! and thank you man, same to you | Football watcher, music listener.\n",
      "Adversarial Text: @CoqBlocker shit yeah that s very true , will do when i m back in england ! and thank you man , same to you | Fｏotball watcher , ⅿusic hearer .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i ==> i\n",
      "music ==> ⅿusic\n",
      "Football ==> Fｏotball\n",
      "listener ==> hearer\n",
      "\n",
      "Original Text:    All i want to do is travel the world | long island. WFVC #c4l\n",
      "Adversarial Text: All i want to do is travel the world | long island . WFC # c4l\n",
      "WFVC ==> WFC\n",
      "\n",
      "Original Text:    Plot twist... When you accidentally find out one of your best friends has been lying to you about their name, age, and relationship status. | live disastrously, love entirely, explore eternally.\n",
      "Adversarial Text: Plot twist ... When you accidentally find out one of your best friends has een lying to you about their name , age , and relationship status . | live disastrously , love entirely , explore eternally .\n",
      "been ==> een\n",
      "\n",
      "Original Text:    @angee_moinette oh yeah !!!! And he still has that radio for help | 29 years old, CA born and raised. Single and NOT ready to mingle.... ;) single mama of a beautiful 2 1/2 year old\n",
      "Adversarial Text: @angee_moinette oh yeah ! ! ! ! And he still has that radio for help | 29 years old , CA born and raised . Single and NOT ready to mingle .... ;) signle mammy of a beautifull 2 1/2 year old\n",
      "beautiful ==> beautifull\n",
      "mama ==> mammy\n",
      "single ==> signle\n",
      "\n",
      "Original Text:    AND WHAT MAKES IT EVEN WORSE is that this Target was in a Black neighborhood!!! I guarantee that at least 65% of the customers are Black. | Christian. Queer. Stanford grad. Writer. Feminist. Organizer. On The Come Up.\n",
      "Adversarial Text: AND WHAT MAKES IT EVEN WORSE is that this Target was in a Black neighborhood ! ! ! I guarante tha at least 65 % of the customers are Black . | Christiaan . Queer . Stanford grad . Writer . Feminist . Organiser . On The Come Up .\n",
      "guarantee ==> guarante\n",
      "Organizer ==> Organiser\n",
      "Christian ==> Christiaan\n",
      "that ==> tha\n",
      "\n",
      "Original Text:    The Halloween 2 remake is so stupid. As well as the Friday the 13th and ANOES remake. The original Halloween remake was good though. | IG- markrrose//mrose381@yahoo.com\n",
      "Adversarial Text: The Halloween 2 remak is so stupid . As well as the Friday the 13th and ΑNOES remake . The original Halloween remake was goodd though . | IG- markrrose//mrose381@yahoo.com\n",
      "ANOES ==> ΑNOES\n",
      "remake ==> remak\n",
      "good ==> goodd\n",
      "\n",
      "Original Text:    Can't wait till I have a house, career and family _ÙÁ_Ù_Ò_ÙÔ¬Û_ÙÔ©Û_ÙÔ¤Û_ÙÔ__ÙÕ_ | Social work student // @jonjotaylor x\n",
      "Adversarial Text: Ca n't wait till I have a house , career and faimly _ ÙÁ_Ù_Ò_ÙÔ¬Û_ÙÔ © Û_ÙÔ¤Û_ÙÔ__ÙÕ _ | Social work student // @jonjotaylor x\n",
      "family ==> faimly\n",
      "\n",
      "Original Text:    @briitstyles the struggle of this drama _Ù÷_ | nan\n",
      "Adversarial Text: @briitstyles the struggle of this drams _ Ù÷ _ | nan\n",
      "drama ==> drams\n",
      "\n",
      "Original Text:    The POLITICS of evidence + results in international development. https://t.co/T7N2c2TTBf - Looks great. h/t @duncan_ids @rosalindeyben + | Following the Money, Opening Governance, Fighting Corruption!                @GlobalIntegrity @OpenGovHub  Tweets my own.\n",
      "Adversarial Text: The POLITICS of evidence + results in international development . https://t.co/T7N2c2TTBf - Looks great . h / t @duncan_ids @rosalindeyben + | Folowing the Money , Opening Goveｒnance , Fighting Corruption !                  @GlobalIntegrity @OpenGovHub    Tweets my own .\n",
      "Governance ==> Goveｒnance\n",
      "Following ==> Folowing\n",
      "\n",
      "Original Text:    Doods are public universities in the US completely for free? Or do you have to pay for something? | Take me back to the basics and the simple life.\n",
      "Adversarial Text: Doods are public universities in the U.S. completely for free ? Or do you have to pay for something ? | Take me back to the basics and the simple life .\n",
      "US ==> U.S.\n",
      "\n",
      "Original Text:    The other day, I tried to come up w/ a curse word that was derived neither from religion nor sex, and couldn't.  @rebecca_roache, thoughts? | #Logician, #Onomast, #Medievalist, and Lecturer in #Philosophy @durham_uni\n",
      "Adversarial Text: The other day , I tried to come up w/ a curse word that was derived neither frok religion nor sex , and could n't .   @rebecca_roache , thoughts ? | # Logician , # Onomast , # Medievalist , and Lecturer in # Philosophy @durham_uni\n",
      "from ==> frok\n",
      "\n",
      "Original Text:    @johncanzanobft just do the math yourselves if you can. Gosh not that tough. | WHO DAT in the pacific northwest. RIP CITY. sec guy. golfer.  i like stuff\n",
      "Adversarial Text: @johncanzanobft just do the math yourselves if you can . Gosh not that tough . | WHO DAT in the pacific northwest . RIP CITY . sec cat . golder .    i like stuff\n",
      "guy ==> cat\n",
      "golfer ==> golder\n",
      "\n",
      "Original Text:    @LucyYaOfficial make most of it and drink heaps !! That's best bday should be!! | life is toooo short to have a bad wine !!! I just love my wine toooo much!!!\n",
      "Adversarial Text: @LucyYaOfficial make most of it and drink heaps ! ! That 's bets bday shoould be ! ! | life is toooo short to have a bad vino ! ! ! I just love my wine toooo much ! ! !\n",
      "wine ==> vino\n",
      "should ==> shoould\n",
      "best ==> bets\n",
      "\n",
      "Original Text:    The realist person I know, my boy #jr. I'm gonna make it happen for us! https://t.co/ChW2VSf3Oj | Exotic Artist from ATL. Breaking down doors and taking no prisoners. If you like my music follow me, I WILL follow back. Like my fb page @jaydotlias. God Bles\n",
      "Adversarial Text: The realist person I know , my boy # jr . I 'm gon na make it hapoen for us ! https://t.co/ChW2VSf3Oj | Exotic Artist from ATL . Breaking down doors and taking no prisoners . If you like my music follow me , I WILL follow back . Like my fb page @jaydotlias . God Bles\n",
      "happen ==> it\n",
      "\n",
      "Original Text:    @WhitneyLaVictor we didn't even get to watch it tho and that was depressinf | If you're offended by anything I say you're probably a pussy ayyyy lmao\n",
      "Adversarial Text: @WhitneyLaVictor we did n't even get to watch it tho and that was depressinf | If you 're offended by anything I say you 're credibly a pusssy ayyyy lmao\n",
      "probably ==> credibly\n",
      "pussy ==> pusssy\n",
      "\n",
      "Original Text:    I literally Hoover it and then do this omg  https://t.co/dcviHKYL0q | 18/A Day To Remember, Neck Deep, other cool bands, cats, pizza, earl grey tea and WWE/Macaron and Lozenger/ III.IX\n",
      "Adversarial Text: I literally Hoover it and then do this omg    https://t.co/dcviHKYL0q | 18/A Day To Remember , Jeck Eeep , other cool bands , cats , pizza , earl grey tea and WWE / Macaron and Lozenger/ III.IX\n",
      "Neck ==> Jeck\n",
      "Deep ==> Eeep\n",
      "\n",
      "Original Text:    Just trying to go home and sleep | I can get you addicted to gambling\n",
      "Adversarial Text: Just trying to go home and sleep | I can incur you addicted to gambling\n",
      "get ==> incur\n",
      "\n",
      "Original Text:    They started 5 weeks apart and both got promoted over the last two weeks! Great job Morgan &amp; Troy @MortonKJ https://t.co/DhStUKeGfU | I work for @TEKsystems and I hire Sales Talent across the Southeast. Reader. Traveler. ECU Alum. MBA Graduate. #RavensNation \n",
      "jeyoung@teksystems.com\n",
      "Adversarial Text: They started 5 weeks apart and both got promoted over the last two weeeks ! Great job Sir & amp ; Trog @MortonKJ https://t.co/DhStUKeGfU | I work for @TEKsystems and I hire Sales Talent across the Southeast . Reader . Traveler . ECU Alum . MBA Graduate . # RavensNation \n",
      "   jeyoung@teksystems.com\n",
      "Troy ==> Trog\n",
      "Morgan ==> Sir\n",
      "weeks ==> weeeks\n",
      "\n",
      "Original Text:    Digging Deep Reveals the Intricate World of Roots #iys15 https://t.co/fSvkFM3tbx | nan\n",
      "Adversarial Text: Digging Deep Reveals the Ｉntricate orld of Foots # iys15 https://t.co/fSvkFM3tbx | nan\n",
      "World ==> orld\n",
      "Roots ==> Foots\n",
      "Intricate ==> Ｉntricate\n",
      "\n",
      "Original Text:    @_kittyL when? I'm off Friday and Saturday _Ù÷Ý | add me on snap: alv_l\n",
      "Adversarial Text: @_kittyL when ? I ' m Ｆriday Friday and Saturday _ Ù÷Ý | add me on catch : alv_l\n",
      "snap ==> on\n",
      "Friday ==> Ｆriday\n",
      "\n",
      "Original Text:    I'm not rockin with the spiders that decide to make their webs and hang right by my garage keypad | Love you forever ZRG 102393/121714 - When the power of love overcomes the love of power, the world will know peace. #feelthebern\n",
      "Adversarial Text: I ' m not rockin with the spiders that decide to make their webs and hang right by barage garage keypad | Love you forever ZRG 102393/121714 - When the mogul of love overcomes the love of power , the world will know peace . # feelthebern\n",
      "power ==> the\n",
      "garage ==> barage\n",
      "\n",
      "Original Text:    American horror story and chill?? | my adventure is just beginning! i love that @nashgrier guyª´ü I make youtube videos w/ @Erin_Dallas01 follow me on ig& musical.ly aubrey_sumler sc:aubreystyles14\n",
      "Adversarial Text: American horror history and chill ? ? | my adventure is kust beginning ! i love that @nashgrier guyª´ü I make youtube videos w/ @Erin_Dallas01 follow me on ig & musical.ly aubrey_sumler sc : aubreystyles14\n",
      "story ==> history\n",
      "just ==> kust\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in ms_E3_H1.iterrows():\n",
    "    if row['success'] == True:\n",
    "        pretty_print(row['doc'], row['adv'], ast.literal_eval(row['indexes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic analysis\n",
    "# Score, average time for adv sample and example, average number of changes per sample, average cost\n",
    "ms_E3_H1   = pd.read_csv('./data/results/both/ms_3_1_timeout.csv')\n",
    "ms_E3_H2   = pd.read_csv('./data/results/both/ms_3_2_timeout.csv')\n",
    "ms_E3_H5   = pd.read_csv('./data/results/both/ms_3_5_timeout.csv')\n",
    "ms_E3_H10  = pd.read_csv('./data/results/both/ms_3_10_timeout.csv')\n",
    "ms_E3_H100 = pd.read_csv('./data/results/both/ms_3_100_timeout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.7792207792207793\n",
      "Average time for sample: 80.7583244085312 std 124.85805133928027\n",
      "Average changes for sample: 1.9166666666666667 std 0.9181805680559546\n",
      "Average cost for sample: 2.969976173123966 std 1.8282529155602278\n"
     ]
    }
   ],
   "source": [
    "# Epsilon = 1\n",
    "score1 = len(ms_E3_H1[ms_E3_H1['success']==True]) / len(ms_E3_H1)\n",
    "print(\"Success rate: {}\".format(score1))\n",
    "# Lower score is due to the time limit for sample. Run again with no limit?\n",
    "\n",
    "meanTime1 = np.mean(ms_E3_H1[ms_E3_H1['success']==True]['time'])\n",
    "stdTime1 = np.std(ms_E3_H1[ms_E3_H1['success']==True]['time'])\n",
    "print(\"Average time for sample: {} std {}\".format(meanTime1, stdTime1))\n",
    "\n",
    "meanChanges1 = np.mean(ms_E3_H1[ms_E3_H1['success']==True]['changes'])\n",
    "stdChanges1 = np.std(ms_E3_H1[ms_E3_H1['success']==True]['changes'])\n",
    "print(\"Average changes for sample: {} std {}\".format(meanChanges1, stdChanges1))\n",
    "\n",
    "meanCost1 = np.mean(ms_E3_H1[ms_E3_H1['success']==True]['cost'])\n",
    "stdCost1 = np.std(ms_E3_H1[ms_E3_H1['success']==True]['cost'])\n",
    "print(\"Average cost for sample: {} std {}\".format(meanCost1, stdCost1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.8831168831168831\n",
      "Average time for sample: 7.626264701871311 std 19.08664559490879\n",
      "Average changes for sample: 2.014705882352941 std 1.0501070962024825\n",
      "Average cost for sample: 3.5759159865624763 std 2.521133697525581\n"
     ]
    }
   ],
   "source": [
    "# Epsilon = 2\n",
    "score2 = len(ms_E3_H2[ms_E3_H2['success']==True]) / len(ms_E3_H2)\n",
    "print(\"Success rate: {}\".format(score2))\n",
    "\n",
    "meanTime2 = np.mean(ms_E3_H2[ms_E3_H2['success']==True]['time'])\n",
    "stdTime2 = np.std(ms_E3_H2[ms_E3_H2['success']==True]['time'])\n",
    "print(\"Average time for sample: {} std {}\".format(meanTime2, stdTime2))\n",
    "\n",
    "meanChanges2 = np.mean(ms_E3_H2[ms_E3_H2['success']==True]['changes'])\n",
    "stdChanges2 = np.std(ms_E3_H2[ms_E3_H2['success']==True]['changes'])\n",
    "print(\"Average changes for sample: {} std {}\".format(meanChanges2, stdChanges2))\n",
    "\n",
    "meanCost2 = np.mean(ms_E3_H2[ms_E3_H2['success']==True]['cost'])\n",
    "stdCost2 = np.std(ms_E3_H2[ms_E3_H2['success']==True]['cost'])\n",
    "print(\"Average cost for sample: {} std {}\".format(meanCost2, stdCost2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.8831168831168831\n",
      "Average time for sample: 6.180394274346969 std 26.186082653531766\n",
      "Average changes for sample: 1.9705882352941178 std 1.0706043954824291\n",
      "Average cost for sample: 3.7401636143160215 std 2.647529757014816\n"
     ]
    }
   ],
   "source": [
    "# Epsilon = 5\n",
    "score5 = len(ms_E3_H5[ms_E3_H5['success']==True]) / len(ms_E3_H5)\n",
    "print(\"Success rate: {}\".format(score5))\n",
    "\n",
    "meanTime5 = np.mean(ms_E3_H5[ms_E3_H5['success']==True]['time'])\n",
    "stdTime5 = np.std(ms_E3_H5[ms_E3_H5['success']==True]['time'])\n",
    "print(\"Average time for sample: {} std {}\".format(meanTime5, stdTime5))\n",
    "\n",
    "meanChanges5 = np.mean(ms_E3_H5[ms_E3_H5['success']==True]['changes'])\n",
    "stdChanges5 = np.std(ms_E3_H5[ms_E3_H5['success']==True]['changes'])\n",
    "print(\"Average changes for sample: {} std {}\".format(meanChanges5, stdChanges5))\n",
    "\n",
    "meanCost5 = np.mean(ms_E3_H5[ms_E3_H5['success']==True]['cost'])\n",
    "stdCost5 = np.std(ms_E3_H5[ms_E3_H5['success']==True]['cost'])\n",
    "print(\"Average cost for sample: {} std {}\".format(meanCost5, stdCost5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.8831168831168831\n",
      "Average time for sample: 7.258663875215194 std 31.19193477825535\n",
      "Average changes for sample: 1.9264705882352942 std 1.0615773013690557\n",
      "Average cost for sample: 3.8339059312334833 std 2.6707636851684233\n"
     ]
    }
   ],
   "source": [
    "# Epsilon = 10\n",
    "score10 = len(ms_E3_H10[ms_E3_H10['success']==True]) / len(ms_E3_H10)\n",
    "print(\"Success rate: {}\".format(score10))\n",
    "\n",
    "meanTime10 = np.mean(ms_E3_H10[ms_E3_H10['success']==True]['time'])\n",
    "stdTime10 = np.std(ms_E3_H10[ms_E3_H10['success']==True]['time'])\n",
    "print(\"Average time for sample: {} std {}\".format(meanTime10, stdTime10))\n",
    "\n",
    "meanChanges10 = np.mean(ms_E3_H10[ms_E3_H10['success']==True]['changes'])\n",
    "stdChanges10 = np.std(ms_E3_H10[ms_E3_H10['success']==True]['changes'])\n",
    "print(\"Average changes for sample: {} std {}\".format(meanChanges10, stdChanges10))\n",
    "\n",
    "meanCost10 = np.mean(ms_E3_H10[ms_E3_H10['success']==True]['cost'])\n",
    "stdCost10 = np.std(ms_E3_H10[ms_E3_H10['success']==True]['cost'])\n",
    "print(\"Average cost for sample: {} std {}\".format(meanCost10, stdCost10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.8831168831168831\n",
      "Average time for sample: 6.2512567884781784 std 31.968560850824666\n",
      "Average changes for sample: 1.911764705882353 std 1.1079298942257272\n",
      "Average cost for sample: 3.918282130294863 std 2.7504861900577153\n"
     ]
    }
   ],
   "source": [
    "# Epsilon = 100\n",
    "score100 = len(ms_E3_H100[ms_E3_H100['success']==True]) / len(ms_E3_H100)\n",
    "print(\"Success rate: {}\".format(score100))\n",
    "\n",
    "meanTime100 = np.mean(ms_E3_H100[ms_E3_H100['success']==True]['time'])\n",
    "stdTime100 = np.std(ms_E3_H100[ms_E3_H100['success']==True]['time'])\n",
    "print(\"Average time for sample: {} std {}\".format(meanTime100, stdTime100))\n",
    "\n",
    "meanChanges100 = np.mean(ms_E3_H100[ms_E3_H100['success']==True]['changes'])\n",
    "stdChanges100 = np.std(ms_E3_H100[ms_E3_H100['success']==True]['changes'])\n",
    "print(\"Average changes for sample: {} std {}\".format(meanChanges100, stdChanges100))\n",
    "\n",
    "meanCost100 = np.mean(ms_E3_H100[ms_E3_H100['success']==True]['cost'])\n",
    "stdCost100 = np.std(ms_E3_H100[ms_E3_H100['success']==True]['cost'])\n",
    "print(\"Average cost for sample: {} std {}\".format(meanCost100, stdCost100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Changes</th>\n",
       "      <th>Mean Time</th>\n",
       "      <th>Std Time</th>\n",
       "      <th>Success rate</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.916667</td>\n",
       "      <td>80.758324</td>\n",
       "      <td>124.858051</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Changes  Mean Time    Std Time  Success rate  epsilon\n",
       "0      1.916667  80.758324  124.858051      0.779221        1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Epsilon Dataframe\n",
    "data = [{'epsilon': 1, 'Success rate': score1, 'Mean Time': meanTime1, 'Std Time': stdTime1, 'Mean Changes': meanChanges1}]\n",
    "d = pd.DataFrame(data)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon  Success rate   Avg Time    Std Time  Avg Changes  Std Changes  Avg Cost  Std Cost\n",
      "      1      0.779221  80.758324  124.858051     1.916667     0.918181  2.969976  1.828253\n",
      "      2      0.883117   7.626265   19.086646     2.014706     1.050107  3.575916  2.521134\n",
      "      5      0.883117   6.180394   26.186083     1.970588     1.070604  3.740164  2.647530\n",
      "     10      0.883117   7.258664   31.191935     1.926471     1.061577  3.833906  2.670764\n",
      "    100      0.883117   6.251257   31.968561     1.911765     1.107930  3.918282  2.750486\n"
     ]
    }
   ],
   "source": [
    "data = {'Epsilon' : [1, 2, 5, 10, 100],\n",
    "        'Success rate': [score1, score2, score5, score10, score100],\n",
    "        'Avg Time': [meanTime1, meanTime2, meanTime5, meanTime10, meanTime100],\n",
    "        'Std Time': [stdTime1, stdTime2, stdTime5, stdTime10, stdTime100],\n",
    "        'Avg Changes': [meanChanges1, meanChanges2, meanChanges5, meanChanges10, meanChanges100],\n",
    "        'Std Changes': [stdChanges1, stdChanges2, stdChanges5, stdChanges10, stdChanges100],\n",
    "        'Avg Cost': [meanCost1, meanCost2, meanCost5, meanCost10, meanCost100],\n",
    "        'Std Cost': [stdCost1, stdCost2, stdCost5, stdCost10, stdCost100],\n",
    "       }\n",
    "d = pd.DataFrame(data, columns=['Epsilon', 'Success rate', 'Avg Time', 'Std Time', 'Avg Changes', 'Std Changes', 'Avg Cost', 'Std Cost'])\n",
    "print(d.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND WHAT MAKES IT EVEN WORSE is that this Target was in a Black neighborhood!!! I guarantee that at least 65% of the customers are Black. | Christian. Queer. Stanford grad. Writer. Feminist. Organizer. On The Come Up.\n",
      "AND WHAT MAKES IT EVEN WORSE is that this Target was in a Black neighborhood ! ! ! I guarante tha at least 65 % of the customers are Black . | Christiaan . Queer . Stanford grad . Writer . Feminist . Organiser . On The Come Up .\n",
      "AND WHAT MAKES IT EVEN WORSE is that this Target was in a Black neighborhood ! ! ! I guarante thаt at least 65 % of the customers are Black . | Christian . Queer . Stanford grad . Weiter . Feminist . Organizer . On The Come Up .\n",
      "AND WHAT MAKES IT EVEN WORSE is that this Target was in a Black neighborhood ! ! ! I guarantee that at least 65 % of the customers are total . | Christian . Queer . Stanford graduate . Writer . Feminiｓt . Organizer . On The Come Up .\n",
      "AND WHAT MAKES IT EVEN WORSE is that this Target was in a Black neighborhood ! ! ! I guarantee that at least 65 % of the customers are total . | Christian . Queer . Stanford graduate . Writer . Ｆeminist . Organizer . On The Come Up .\n",
      "AND WHAT MAKES IT EVEN WORSE is that this Target was in a Black neighborhood ! ! ! I guarantee that at least 65 % of the customers are Black . | Christian . Queer . Stanford ｇrad . Writer . Femⅰnist . Organizer . On The Come Up .\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "sample = 57\n",
    "print(ms_E3_H1['doc'][sample])\n",
    "print(ms_E3_H1['adv'][sample])\n",
    "print(ms_E3_H2['adv'][sample])\n",
    "print(ms_E3_H5['adv'][sample])\n",
    "print(ms_E3_H10['adv'][sample])\n",
    "print(ms_E3_H100['adv'][sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only synonyms, only typos, both (expansion=1, epsilon=1)\n",
    "# Score, average time for sample\n",
    "only_syn   = pd.read_csv('./data/results/only_syn/ms_1_1.csv')\n",
    "only_typos = pd.read_csv('./data/results/only_typos/ms_1_1.csv')\n",
    "both       = pd.read_csv('./data/results/both/ms_1_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate only synonyms: 0.4155844155844156\n",
      "Success rate only typos: 0.7402597402597403\n",
      "Success rate both: 0.7662337662337663\n"
     ]
    }
   ],
   "source": [
    "score1 = len(only_syn[only_syn['success']==True]) / len(only_syn)\n",
    "print(\"Success rate only synonyms: {}\".format(score1))\n",
    "score2 = len(only_typos[only_typos['success']==True]) / len(only_typos)\n",
    "print(\"Success rate only typos: {}\".format(score2))\n",
    "score3 = len(both[both['success']==True]) / len(both)\n",
    "print(\"Success rate both: {}\".format(score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only synonyms: Average time for sample: 5.538400389254093 std 7.248973529213859\n",
      "Only typos: Average time for sample: 44.67684885911774 std 90.93769195960502\n",
      "Both: Average time for sample: 193.57323061409645 std 984.8666658095351\n"
     ]
    }
   ],
   "source": [
    "meanTime1 = np.mean(only_syn[only_syn['success']==True]['time'])\n",
    "stdTime1 = np.std(only_syn[only_syn['success']==True]['time'])\n",
    "print(\"Only synonyms: Average time for sample: {} std {}\".format(meanTime1, stdTime1))\n",
    "meanTime2 = np.mean(only_typos[only_typos['success']==True]['time'])\n",
    "stdTime2 = np.std(only_typos[only_typos['success']==True]['time'])\n",
    "print(\"Only typos: Average time for sample: {} std {}\".format(meanTime2, stdTime2))\n",
    "meanTime3 = np.mean(both[both['success']==True]['time'])\n",
    "stdTime3 = np.std(both[both['success']==True]['time'])\n",
    "print(\"Both: Average time for sample: {} std {}\".format(meanTime3, stdTime3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success rate</th>\n",
       "      <th>Avg Time</th>\n",
       "      <th>Std Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Only synonyms</th>\n",
       "      <td>0.415584</td>\n",
       "      <td>5.538400</td>\n",
       "      <td>7.248974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Only typos</th>\n",
       "      <td>0.740260</td>\n",
       "      <td>44.676849</td>\n",
       "      <td>90.937692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Both</th>\n",
       "      <td>0.766234</td>\n",
       "      <td>193.573231</td>\n",
       "      <td>984.866666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Success rate    Avg Time    Std Time\n",
       "Only synonyms      0.415584    5.538400    7.248974\n",
       "Only typos         0.740260   44.676849   90.937692\n",
       "Both               0.766234  193.573231  984.866666"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Success rate': [score1, score2, score3],\n",
    "        'Avg Time': [meanTime1, meanTime2, meanTime3],\n",
    "        'Std Time': [stdTime1, stdTime2, stdTime3],\n",
    "       }\n",
    "d = pd.DataFrame(data, \n",
    "                 columns=['Success rate', 'Avg Time', 'Std Time'], \n",
    "                 index=['Only synonyms', 'Only typos', 'Both']\n",
    "                )\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Garge0 @TrYHARD_CupCAkE i know lol the earliest my connects get them is the friday before release | An actual @WeAreDooMClan member!!\n",
      "@Garge0 @TrYHARD_CupCAkE i know lol the earliest my connects get them is the friday in press | An literal @WeAreDooMClan extremity ! !\n",
      "@Garge0 @TrYHARD_CupCAkE i know lol the earliest my connects get them is the friday before release | An actua @WeAreDooMϹlan membre ! !\n",
      "@Garge0 @TrYHARD_CupCAkE i know lol the earliest my connects get them is the friday before release | An literal @WeAreDooMClan ember ! !\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "sample = 5\n",
    "print(only_syn['doc'][sample])\n",
    "print(only_syn['adv'][sample])\n",
    "print(only_typos['adv'][sample])\n",
    "print(both['adv'][sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Heuristic\n",
    "# Score, average time for sample\n",
    "vsn_simil = pd.read_csv('./data/results/only_syn/e3_noheu_costVsn.csv')\n",
    "cost1     = pd.read_csv('./data/results/only_typos/e3_noheu_cost1.csv')\n",
    "L2norm    = pd.read_csv('./data/results/both/e3_noheu_costL2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate only synonym - vsn similarity: 0.65\n",
      "Success rate only typos - cost 1: 0.8923076923076924\n",
      "Success rate both - L2 norm: 0.8974358974358975\n"
     ]
    }
   ],
   "source": [
    "score1 = len(vsn_simil[vsn_simil['success']==True]) / len(vsn_simil)\n",
    "print(\"Success rate only synonym - vsn similarity: {}\".format(score1))\n",
    "score2 = len(cost1[cost1['success']==True]) / len(cost1)\n",
    "print(\"Success rate only typos - cost 1: {}\".format(score2))\n",
    "score3 = len(L2norm[L2norm['success']==True]) / len(L2norm)\n",
    "print(\"Success rate both - L2 norm: {}\".format(score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vsn similarity: Average time for sample: 171.87880948873666 std 191.87434107172862\n",
      "Cost 1: Average time for sample: 1295.9196191820606 std 4808.059265131845\n",
      "Both: Average time for sample: 7371.979027421134 std 14924.57239115634\n"
     ]
    }
   ],
   "source": [
    "meanTime1 = np.mean(vsn_simil[vsn_simil['success']==True]['time'])\n",
    "stdTime1 = np.std(vsn_simil[vsn_simil['success']==True]['time'])\n",
    "print(\"Vsn similarity: Average time for sample: {} std {}\".format(meanTime1, stdTime1))\n",
    "meanTime2 = np.mean(cost1[cost1['success']==True]['time'])\n",
    "stdTime2 = np.std(cost1[cost1['success']==True]['time'])\n",
    "print(\"Cost 1: Average time for sample: {} std {}\".format(meanTime2, stdTime2))\n",
    "meanTime3 = np.mean(L2norm[L2norm['success']==True]['time'])\n",
    "stdTime3 = np.std(L2norm[L2norm['success']==True]['time'])\n",
    "print(\"Both: Average time for sample: {} std {}\".format(meanTime3, stdTime3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vsn_simil: Average cost for sample: 1.482932688417843 std 0.6213848349154776\n",
      "cost1: Average cost for sample only heu: 1.7758620689655173 std 0.9292767571180598\n",
      "L2norm: Average cost for sample only cost: 3.431966449293707 std 2.2191161778237984\n"
     ]
    }
   ],
   "source": [
    "meanCost = np.mean(vsn_simil[vsn_simil['success']==True]['cost'])\n",
    "stdCost = np.std(vsn_simil[vsn_simil['success']==True]['cost'])\n",
    "print(\"vsn_simil: Average cost for sample: {} std {}\".format(meanCost, stdCost))\n",
    "meanCost = np.mean(cost1[cost1['success']==True]['cost'])\n",
    "stdCost = np.std(cost1[cost1['success']==True]['cost'])\n",
    "print(\"cost1: Average cost for sample only heu: {} std {}\".format(meanCost, stdCost))\n",
    "meanCost = np.mean(L2norm[L2norm['success']==True]['cost'])\n",
    "stdCost = np.std(L2norm[L2norm['success']==True]['cost'])\n",
    "print(\"L2norm: Average cost for sample only cost: {} std {}\".format(meanCost, stdCost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success rate</th>\n",
       "      <th>Avg Time</th>\n",
       "      <th>Std Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Only synonyms - vsn similarity</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>171.878809</td>\n",
       "      <td>191.874341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Only typos - cost 1</th>\n",
       "      <td>0.892308</td>\n",
       "      <td>1295.919619</td>\n",
       "      <td>4808.059265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Both - L2 norm</th>\n",
       "      <td>0.897436</td>\n",
       "      <td>7371.979027</td>\n",
       "      <td>14924.572391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Success rate     Avg Time      Std Time\n",
       "Only synonyms - vsn similarity      0.650000   171.878809    191.874341\n",
       "Only typos - cost 1                 0.892308  1295.919619   4808.059265\n",
       "Both - L2 norm                      0.897436  7371.979027  14924.572391"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Success rate': [score1, score2, score3],\n",
    "        'Avg Time': [meanTime1, meanTime2, meanTime3],\n",
    "        'Std Time': [stdTime1, stdTime2, stdTime3],\n",
    "       }\n",
    "d = pd.DataFrame(data, \n",
    "                 columns=['Success rate', 'Avg Time', 'Std Time'], \n",
    "                 index=['Only synonyms - vsn similarity', 'Only typos - cost 1', 'Both - L2 norm']\n",
    "                )\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A* vs Greedy BFS vs Hill Climbing (expansion=3, epsilon=5)\n",
    "# Note: Hill Climbing no limit in graph depth\n",
    "# Score, average time for sample, average number of changes\n",
    "a_star = pd.read_csv('./data/results/both/ms_3_5.csv')\n",
    "bfs    = pd.read_csv('./data/results/both/bfs_ms_3_5.csv')\n",
    "hill   = pd.read_csv('./data/results/both/hill_ms_3_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate A*: 0.8831168831168831\n",
      "Success rate BFS: 0.8831168831168831\n",
      "Success rate Hill Climbing: 0.987012987012987\n"
     ]
    }
   ],
   "source": [
    "score = len(a_star[a_star['success']==True]) / len(a_star)\n",
    "print(\"Success rate A*: {}\".format(score))\n",
    "score = len(bfs[bfs['success']==True]) / len(bfs)\n",
    "print(\"Success rate BFS: {}\".format(score))\n",
    "score = len(hill[hill['success']==True]) / len(hill)\n",
    "print(\"Success rate Hill Climbing: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*: Average time for sample: 13.51524604769314 std 50.75786712894975\n",
      "BFS: Average time for sample: 4.839642026845147 std 24.732600760038395\n",
      "Hill Climbing: Average time for sample: 3.2286512632119027 std 3.48007079021477\n"
     ]
    }
   ],
   "source": [
    "meanTime = np.mean(a_star[a_star['success']==True]['time'])\n",
    "stdTime = np.std(a_star[a_star['success']==True]['time'])\n",
    "print(\"A*: Average time for sample: {} std {}\".format(meanTime, stdTime))\n",
    "meanTime = np.mean(bfs[bfs['success']==True]['time'])\n",
    "stdTime = np.std(bfs[bfs['success']==True]['time'])\n",
    "print(\"BFS: Average time for sample: {} std {}\".format(meanTime, stdTime))\n",
    "meanTime = np.mean(hill[hill['success']==True]['time'])\n",
    "stdTime = np.std(hill[hill['success']==True]['time'])\n",
    "print(\"Hill Climbing: Average time for sample: {} std {}\".format(meanTime, stdTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*: Average changes for sample: 1.9558823529411764 std 1.0492829979031306\n",
      "BFS: Average changes for sample: 1.911764705882353 std 1.0945761215251997\n",
      "Hill Climbing: Average changes for sample: 3.5789473684210527 std 4.1998219194538065\n"
     ]
    }
   ],
   "source": [
    "meanChanges = np.mean(a_star[a_star['success']==True]['changes'])\n",
    "stdChanges = np.std(a_star[a_star['success']==True]['changes'])\n",
    "print(\"A*: Average changes for sample: {} std {}\".format(meanChanges, stdChanges))\n",
    "meanChanges = np.mean(bfs[bfs['success']==True]['changes'])\n",
    "stdChanges = np.std(bfs[bfs['success']==True]['changes'])\n",
    "print(\"BFS: Average changes for sample: {} std {}\".format(meanChanges, stdChanges))\n",
    "meanChanges = np.mean(hill[hill['success']==True]['changes'])\n",
    "stdChanges = np.std(hill[hill['success']==True]['changes'])\n",
    "print(\"Hill Climbing: Average changes for sample: {} std {}\".format(meanChanges, stdChanges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*: Average cost for sample: 3.7425656067755293 std 2.678290766893157\n",
      "BFS: Average cost for sample: 0.0 std 0.0\n",
      "Hill Climbing: Average cost for sample: 4.630150849421936 std 4.458741538426261\n"
     ]
    }
   ],
   "source": [
    "meanCost = np.mean(a_star[a_star['success']==True]['cost'])\n",
    "stdCost = np.std(a_star[a_star['success']==True]['cost'])\n",
    "print(\"A*: Average cost for sample: {} std {}\".format(meanCost, stdCost))\n",
    "meanCost = np.mean(bfs[bfs['success']==True]['cost'])\n",
    "stdCost = np.std(bfs[bfs['success']==True]['cost'])\n",
    "print(\"BFS: Average cost for sample: {} std {}\".format(meanCost, stdCost))\n",
    "meanCost = np.mean(hill[hill['success']==True]['cost'])\n",
    "stdCost = np.std(hill[hill['success']==True]['cost'])\n",
    "print(\"Hill Climbing: Average cost for sample: {} std {}\".format(meanCost, stdCost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A* vs Greedy BFS vs Hill Climbing (expansion=3, epsilon=5)\n",
    "# Note: Hill Climbing no limit in graph depth\n",
    "# Score, average time for sample, average number of changes\n",
    "a_star = pd.read_csv('./data/results/both/astar_3_5_level7_300.csv')\n",
    "ida_star = pd.read_csv('./data/results/both/idastar_3_5_level7_300.csv')\n",
    "bfs    = pd.read_csv('./data/results/both/bfs_3_5_level7_300.csv')\n",
    "hill   = pd.read_csv('./data/results/both/hill_3_5_level7_300.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate A*: 0.9419642857142857\n",
      "Success rate IDA*: 0.8705357142857143\n",
      "Success rate BFS: 0.9464285714285714\n",
      "Success rate Hill Climbing: 0.8973214285714286\n"
     ]
    }
   ],
   "source": [
    "score1 = len(a_star[a_star['success']==True]) / len(a_star)\n",
    "print(\"Success rate A*: {}\".format(score1))\n",
    "score4 = len(ida_star[ida_star['success']==True]) / len(ida_star)\n",
    "print(\"Success rate IDA*: {}\".format(score4))\n",
    "score2 = len(bfs[bfs['success']==True]) / len(bfs)\n",
    "print(\"Success rate BFS: {}\".format(score2))\n",
    "score3 = len(hill[hill['success']==True]) / len(hill)\n",
    "print(\"Success rate Hill Climbing: {}\".format(score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*: Average time for sample: 5.559862127801253 std 28.803589673852\n",
      "IDA*: Average time for sample: 17.968122418721517 std 60.1854478690134\n",
      "BFS: Average time for sample: 8.579537292696395 std 54.760753033483596\n",
      "Hill Climbing: Average time for sample: 2.5894279586735056 std 2.1880961327945285\n"
     ]
    }
   ],
   "source": [
    "meanTime1 = np.mean(a_star[a_star['success']==True]['time'])\n",
    "stdTime1 = np.std(a_star[a_star['success']==True]['time'])\n",
    "print(\"A*: Average time for sample: {} std {}\".format(meanTime1, stdTime1))\n",
    "meanTime4 = np.mean(ida_star[ida_star['success']==True]['time'])\n",
    "stdTime4 = np.std(ida_star[ida_star['success']==True]['time'])\n",
    "print(\"IDA*: Average time for sample: {} std {}\".format(meanTime4, stdTime4))\n",
    "meanTime2 = np.mean(bfs[bfs['success']==True]['time'])\n",
    "stdTime2 = np.std(bfs[bfs['success']==True]['time'])\n",
    "print(\"BFS: Average time for sample: {} std {}\".format(meanTime2, stdTime2))\n",
    "meanTime3 = np.mean(hill[hill['success']==True]['time'])\n",
    "stdTime3 = np.std(hill[hill['success']==True]['time'])\n",
    "print(\"Hill Climbing: Average time for sample: {} std {}\".format(meanTime3, stdTime3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*: Average changes for sample: 2.6303317535545023 std 1.9679492017213485\n",
      "IDA*: Average changes for sample: 3.2051282051282053 std 1.1272723416643353\n",
      "BFS: Average changes for sample: 2.5754716981132075 std 1.9640548795677069\n",
      "Hill Climbing: Average changes for sample: 2.8059701492537314 std 2.00178134081182\n"
     ]
    }
   ],
   "source": [
    "meanChanges1 = np.mean(a_star[a_star['success']==True]['changes'])\n",
    "stdChanges1 = np.std(a_star[a_star['success']==True]['changes'])\n",
    "print(\"A*: Average changes for sample: {} std {}\".format(meanChanges1, stdChanges1))\n",
    "meanChanges4 = np.mean(ida_star[ida_star['success']==True]['changes'])\n",
    "stdChanges4 = np.std(ida_star[ida_star['success']==True]['changes'])\n",
    "print(\"IDA*: Average changes for sample: {} std {}\".format(meanChanges4, stdChanges4))\n",
    "meanChanges2 = np.mean(bfs[bfs['success']==True]['changes'])\n",
    "stdChanges2 = np.std(bfs[bfs['success']==True]['changes'])\n",
    "print(\"BFS: Average changes for sample: {} std {}\".format(meanChanges2, stdChanges2))\n",
    "meanChanges3 = np.mean(hill[hill['success']==True]['changes'])\n",
    "stdChanges3 = np.std(hill[hill['success']==True]['changes'])\n",
    "print(\"Hill Climbing: Average changes for sample: {} std {}\".format(meanChanges3, stdChanges3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*: Average cost for sample: 4.635797382798046 std 3.9949971380902456\n",
      "IDA*: Average cost for sample: 4.486712072040432 std 2.9655082373363086\n",
      "BFS: Average cost for sample: 0.0 std 0.0\n",
      "Hill Climbing: Average cost for sample: 4.243978007017769 std 3.359779193881547\n"
     ]
    }
   ],
   "source": [
    "meanCost1 = np.mean(a_star[a_star['success']==True]['cost'])\n",
    "stdCost1 = np.std(a_star[a_star['success']==True]['cost'])\n",
    "print(\"A*: Average cost for sample: {} std {}\".format(meanCost1, stdCost1))\n",
    "meanCost4 = np.mean(ida_star[ida_star['success']==True]['cost'])\n",
    "stdCost4 = np.std(ida_star[ida_star['success']==True]['cost'])\n",
    "print(\"IDA*: Average cost for sample: {} std {}\".format(meanCost4, stdCost4))\n",
    "meanCost2 = np.mean(bfs[bfs['success']==True]['cost'])\n",
    "stdCost2 = np.std(bfs[bfs['success']==True]['cost'])\n",
    "print(\"BFS: Average cost for sample: {} std {}\".format(meanCost2, stdCost2))\n",
    "meanCost3 = np.mean(hill[hill['success']==True]['cost'])\n",
    "stdCost3 = np.std(hill[hill['success']==True]['cost'])\n",
    "print(\"Hill Climbing: Average cost for sample: {} std {}\".format(meanCost3, stdCost3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success rate</th>\n",
       "      <th>Avg Time</th>\n",
       "      <th>Std Time</th>\n",
       "      <th>Avg Changes</th>\n",
       "      <th>Std Changes</th>\n",
       "      <th>Avg Cost</th>\n",
       "      <th>Std Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A*</th>\n",
       "      <td>0.941964</td>\n",
       "      <td>5.559862</td>\n",
       "      <td>28.803590</td>\n",
       "      <td>2.630332</td>\n",
       "      <td>1.967949</td>\n",
       "      <td>4.635797</td>\n",
       "      <td>3.994997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDA*</th>\n",
       "      <td>0.870536</td>\n",
       "      <td>17.968122</td>\n",
       "      <td>60.185448</td>\n",
       "      <td>3.205128</td>\n",
       "      <td>1.127272</td>\n",
       "      <td>4.486712</td>\n",
       "      <td>2.965508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFS</th>\n",
       "      <td>0.946429</td>\n",
       "      <td>8.579537</td>\n",
       "      <td>54.760753</td>\n",
       "      <td>2.575472</td>\n",
       "      <td>1.964055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hill Climbing</th>\n",
       "      <td>0.897321</td>\n",
       "      <td>2.589428</td>\n",
       "      <td>2.188096</td>\n",
       "      <td>2.805970</td>\n",
       "      <td>2.001781</td>\n",
       "      <td>4.243978</td>\n",
       "      <td>3.359779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Success rate   Avg Time   Std Time  Avg Changes  Std Changes  \\\n",
       "A*                 0.941964   5.559862  28.803590     2.630332     1.967949   \n",
       "IDA*               0.870536  17.968122  60.185448     3.205128     1.127272   \n",
       "BFS                0.946429   8.579537  54.760753     2.575472     1.964055   \n",
       "Hill Climbing      0.897321   2.589428   2.188096     2.805970     2.001781   \n",
       "\n",
       "               Avg Cost  Std Cost  \n",
       "A*             4.635797  3.994997  \n",
       "IDA*           4.486712  2.965508  \n",
       "BFS            0.000000  0.000000  \n",
       "Hill Climbing  4.243978  3.359779  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "        'Success rate': [score1, score4, score2, score3],\n",
    "        'Avg Time': [meanTime1, meanTime4, meanTime2, meanTime3],\n",
    "        'Std Time': [stdTime1, stdTime4, stdTime2, stdTime3],\n",
    "        'Avg Changes': [meanChanges1, meanChanges4, meanChanges2, meanChanges3],\n",
    "        'Std Changes': [stdChanges1, stdChanges4, stdChanges2, stdChanges3],\n",
    "        'Avg Cost': [meanCost1, meanCost4, meanCost2, meanCost3],\n",
    "        'Std Cost': [stdCost1, stdCost4, stdCost2, stdCost3],\n",
    "       }\n",
    "d = pd.DataFrame(data, \n",
    "                 columns=['Success rate', 'Avg Time', 'Std Time', 'Avg Changes', 'Std Changes', 'Avg Cost', 'Std Cost'],\n",
    "                 index=['A*','IDA*', 'BFS', 'Hill Climbing'])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A* vs Greedy BFS vs Hill Climbing (expansion=3, epsilon=5)\n",
    "# Note: Hill Climbing no limit in graph depth\n",
    "# Score, average time for sample, average number of changes\n",
    "a_star = pd.read_csv('./data/results/both/astar_3_5_level7_300.csv')\n",
    "a_star_onlyheu = pd.read_csv('./data/results/both/heu_distance.csv')\n",
    "a_star_onlycost = pd.read_csv('./data/results/both/e3_noheu_costL2.csv')\n",
    "#a_star_onlycost = a_star_onlycost[a_star_onlycost['time']<5000]\n",
    "a_star_onlyheu = a_star_onlyheu[a_star_onlyheu['time']<1800]\n",
    "a_star = a_star[a_star['time']<1800]\n",
    "\n",
    "ida_star = pd.read_csv('./data/results/both/idastar_3_5_level7_300.csv')\n",
    "bfs    = pd.read_csv('./data/results/both/bfs_3_5_level7_300.csv')\n",
    "\n",
    "hill   = pd.read_csv('./data/results/both/hill_3_5_level7_300.csv')\n",
    "hill_onlycost = pd.read_csv('./data/results/both/hillclimbing_onlycost_300.csv')\n",
    "hill_onlyheu = pd.read_csv('./data/results/both/hillclimbing_onlyheu_300.csv')\n",
    "hill   = pd.read_csv('./data/results/both/hill_3_5_level7_300.csv')\n",
    "hill = hill[hill['time']<1800]\n",
    "hill_onlycost = hill_onlycost[hill_onlycost['time']<1800]\n",
    "hill_onlyheu = hill_onlyheu[hill_onlyheu['time']<1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "224\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-984b94d48d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_star_onlycost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_star_onlycost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'doc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_star_onlycost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_star\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2167\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2168\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2169\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2170\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:3557)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:3240)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas/hashtable.c:8564)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas/hashtable.c:8508)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 50"
     ]
    }
   ],
   "source": [
    "number = 50\n",
    "print(len(a_star_onlycost))\n",
    "print(len(a_star))\n",
    "print(a_star_onlycost['doc'][number])\n",
    "print(a_star_onlycost['adv'][number])\n",
    "print(a_star['adv'][number])\n",
    "print(a_star_onlycost['time'][number])\n",
    "print(a_star['time'][number])\n",
    "print(a_star_onlycost['cost'][number])\n",
    "print(a_star['cost'][number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate A*: 0.9419642857142857\n",
      "Success rate A* only heu: 0.9444444444444444\n",
      "Success rate A* only cost: 0.8974358974358975\n",
      "Success rate Hill Climbing: 0.8973214285714286\n",
      "Success rate Hill Climbing only cost: 0.05357142857142857\n",
      "Success rate Hill Climbing only heu: 0.8973214285714286\n"
     ]
    }
   ],
   "source": [
    "score = len(a_star[a_star['success']==True]) / len(a_star)\n",
    "print(\"Success rate A*: {}\".format(score))\n",
    "score = len(a_star_onlyheu[a_star_onlyheu['success']==True]) / len(a_star_onlyheu)\n",
    "print(\"Success rate A* only heu: {}\".format(score))\n",
    "score = len(a_star_onlycost[a_star_onlycost['success']==True]) / len(a_star_onlycost)\n",
    "print(\"Success rate A* only cost: {}\".format(score))\n",
    "\n",
    "# score = len(ida_star[ida_star['success']==True]) / len(ida_star)\n",
    "# print(\"Success rate IDA*: {}\".format(score))\n",
    "# score = len(bfs[bfs['success']==True]) / len(bfs)\n",
    "# print(\"Success rate BFS: {}\".format(score))\n",
    "\n",
    "score = len(hill[hill['success']==True]) / len(hill)\n",
    "print(\"Success rate Hill Climbing: {}\".format(score))\n",
    "score = len(hill_onlycost[hill_onlycost['success']==True]) / len(hill_onlycost)\n",
    "print(\"Success rate Hill Climbing only cost: {}\".format(score))\n",
    "score = len(hill_onlyheu[hill_onlyheu['success']==True]) / len(hill_onlyheu)\n",
    "print(\"Success rate Hill Climbing only heu: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*: Average time for sample: 5.559862127801253 std 28.803589673852\n",
      "A*: Average time for sample only heu: 6.905381865361157 std 23.686921435643317\n",
      "A*: Average time for sample only cost: 7371.979027421134 std 14924.57239115634\n",
      "Hill Climbing: Average time for sample: 2.5894279586735056 std 2.1880961327945285\n",
      "Hill Climbing: Average time for sample only cost: 3.1469539999961853 std 2.800267776163444\n",
      "Hill Climbing: Average time for sample only heu: 1.955940355708943 std 1.6861650559033228\n"
     ]
    }
   ],
   "source": [
    "meanTime = np.mean(a_star[a_star['success']==True]['time'])\n",
    "stdTime = np.std(a_star[a_star['success']==True]['time'])\n",
    "print(\"A*: Average time for sample: {} std {}\".format(meanTime, stdTime))\n",
    "meanTime = np.mean(a_star_onlyheu[a_star_onlyheu['success']==True]['time'])\n",
    "stdTime = np.std(a_star_onlyheu[a_star_onlyheu['success']==True]['time'])\n",
    "print(\"A*: Average time for sample only heu: {} std {}\".format(meanTime, stdTime))\n",
    "meanTime = np.mean(a_star_onlycost[a_star_onlycost['success']==True]['time'])\n",
    "stdTime = np.std(a_star_onlycost[a_star_onlycost['success']==True]['time'])\n",
    "print(\"A*: Average time for sample only cost: {} std {}\".format(meanTime, stdTime))\n",
    "\n",
    "# meanTime = np.mean(ida_star[ida_star['success']==True]['time'])\n",
    "# stdTime = np.std(ida_star[ida_star['success']==True]['time'])\n",
    "# print(\"IDA*: Average time for sample: {} std {}\".format(meanTime, stdTime))\n",
    "# meanTime = np.mean(bfs[bfs['success']==True]['time'])\n",
    "# stdTime = np.std(bfs[bfs['success']==True]['time'])\n",
    "# print(\"BFS: Average time for sample: {} std {}\".format(meanTime, stdTime))\n",
    "\n",
    "meanTime = np.mean(hill[hill['success']==True]['time'])\n",
    "stdTime = np.std(hill[hill['success']==True]['time'])\n",
    "print(\"Hill Climbing: Average time for sample: {} std {}\".format(meanTime, stdTime))\n",
    "\n",
    "meanTime = np.mean(hill_onlycost[hill_onlycost['success']==True]['time'])\n",
    "stdTime = np.std(hill_onlycost[hill_onlycost['success']==True]['time'])\n",
    "print(\"Hill Climbing: Average time for sample only cost: {} std {}\".format(meanTime, stdTime))\n",
    "\n",
    "meanTime = np.mean(hill_onlyheu[hill_onlyheu['success']==True]['time'])\n",
    "stdTime = np.std(hill_onlyheu[hill_onlyheu['success']==True]['time'])\n",
    "print(\"Hill Climbing: Average time for sample only heu: {} std {}\".format(meanTime, stdTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*: Average changes for sample: 2.6303317535545023 std 1.9679492017213485\n",
      "A*: Average changes for sample only heu: 1.838235294117647 std 0.9942525143461984\n",
      "A*: Average changes for sample only cost: 2.257142857142857 std 1.05133539959852\n",
      "Hill Climbing: Average changes for sample: 2.8059701492537314 std 2.00178134081182\n",
      "Hill Climbing: Average changes for sample only cost: 4.083333333333333 std 2.812422838447701\n",
      "Hill Climbing: Average changes for sample only heu: 2.6069651741293534 std 1.8978257378182715\n"
     ]
    }
   ],
   "source": [
    "meanChanges = np.mean(a_star[a_star['success']==True]['changes'])\n",
    "stdChanges = np.std(a_star[a_star['success']==True]['changes'])\n",
    "print(\"A*: Average changes for sample: {} std {}\".format(meanChanges, stdChanges))\n",
    "meanChanges = np.mean(a_star_onlyheu[a_star_onlyheu['success']==True]['changes'])\n",
    "stdChanges = np.std(a_star_onlyheu[a_star_onlyheu['success']==True]['changes'])\n",
    "print(\"A*: Average changes for sample only heu: {} std {}\".format(meanChanges, stdChanges))\n",
    "meanChanges = np.mean(a_star_onlycost[a_star_onlycost['success']==True]['changes'])\n",
    "stdChanges = np.std(a_star_onlycost[a_star_onlycost['success']==True]['changes'])\n",
    "print(\"A*: Average changes for sample only cost: {} std {}\".format(meanChanges, stdChanges))\n",
    "\n",
    "# meanChanges = np.mean(ida_star[ida_star['success']==True]['changes'])\n",
    "# stdChanges = np.std(ida_star[ida_star['success']==True]['changes'])\n",
    "# print(\"IDA*: Average changes for sample: {} std {}\".format(meanChanges, stdChanges))\n",
    "# meanChanges = np.mean(bfs[bfs['success']==True]['changes'])\n",
    "# stdChanges = np.std(bfs[bfs['success']==True]['changes'])\n",
    "# print(\"BFS: Average changes for sample: {} std {}\".format(meanChanges, stdChanges))\n",
    "\n",
    "meanChanges = np.mean(hill[hill['success']==True]['changes'])\n",
    "stdChanges = np.std(hill[hill['success']==True]['changes'])\n",
    "print(\"Hill Climbing: Average changes for sample: {} std {}\".format(meanChanges, stdChanges))\n",
    "\n",
    "meanChanges = np.mean(hill_onlycost[hill_onlycost['success']==True]['changes'])\n",
    "stdChanges = np.std(hill_onlycost[hill_onlycost['success']==True]['changes'])\n",
    "print(\"Hill Climbing: Average changes for sample only cost: {} std {}\".format(meanChanges, stdChanges))\n",
    "\n",
    "meanChanges = np.mean(hill_onlyheu[hill_onlyheu['success']==True]['changes'])\n",
    "stdChanges = np.std(hill_onlyheu[hill_onlyheu['success']==True]['changes'])\n",
    "print(\"Hill Climbing: Average changes for sample only heu: {} std {}\".format(meanChanges, stdChanges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*: Average cost for sample: 4.635797382798046 std 3.9949971380902456\n",
      "A*: Average cost for sample only heu: 0.0 std 0.0\n",
      "A*: Average cost for sample only cost: 3.431966449293707 std 2.2191161778237984\n",
      "Hill Climbing: Average cost for sample: 4.243978007017769 std 3.359779193881547\n",
      "Hill Climbing: Average cost for sample only cost: 2.286985453645078 std 1.8440823593626683\n",
      "Hill Climbing: Average cost for sample only heu: 0.0 std 0.0\n"
     ]
    }
   ],
   "source": [
    "meanCost = np.mean(a_star[a_star['success']==True]['cost'])\n",
    "stdCost = np.std(a_star[a_star['success']==True]['cost'])\n",
    "print(\"A*: Average cost for sample: {} std {}\".format(meanCost, stdCost))\n",
    "meanCost = np.mean(a_star_onlyheu[a_star_onlyheu['success']==True]['cost'])\n",
    "stdCost = np.std(a_star_onlyheu[a_star_onlyheu['success']==True]['cost'])\n",
    "print(\"A*: Average cost for sample only heu: {} std {}\".format(meanCost, stdCost))\n",
    "meanCost = np.mean(a_star_onlycost[a_star_onlycost['success']==True]['cost'])\n",
    "stdCost = np.std(a_star_onlycost[a_star_onlycost['success']==True]['cost'])\n",
    "print(\"A*: Average cost for sample only cost: {} std {}\".format(meanCost, stdCost))\n",
    "\n",
    "# meanCost = np.mean(ida_star[ida_star['success']==True]['cost'])\n",
    "# stdCost = np.std(ida_star[ida_star['success']==True]['cost'])\n",
    "# print(\"IDA*: Average cost for sample: {} std {}\".format(meanCost, stdCost))\n",
    "# meanCost = np.mean(bfs[bfs['success']==True]['cost'])\n",
    "# stdCost = np.std(bfs[bfs['success']==True]['cost'])\n",
    "# print(\"BFS: Average cost for sample: {} std {}\".format(meanCost, stdCost))\n",
    "meanCost = np.mean(hill[hill['success']==True]['cost'])\n",
    "stdCost = np.std(hill[hill['success']==True]['cost'])\n",
    "print(\"Hill Climbing: Average cost for sample: {} std {}\".format(meanCost, stdCost))\n",
    "\n",
    "meanCost = np.mean(hill_onlycost[hill_onlycost['success']==True]['cost'])\n",
    "stdCost = np.std(hill_onlycost[hill_onlycost['success']==True]['cost'])\n",
    "print(\"Hill Climbing: Average cost for sample only cost: {} std {}\".format(meanCost, stdCost))\n",
    "\n",
    "meanCost = np.mean(hill_onlyheu[hill_onlyheu['success']==True]['cost'])\n",
    "stdCost = np.std(hill_onlyheu[hill_onlyheu['success']==True]['cost'])\n",
    "print(\"Hill Climbing: Average cost for sample only heu: {} std {}\".format(meanCost, stdCost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heu test\n",
    "# Score, average time for sample\n",
    "confidence = pd.read_csv('./data/results/both/heu_confidence.csv')\n",
    "distance   = pd.read_csv('./data/results/both/heu_distance.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate confidence: 0.8051948051948052\n",
      "Success rate confidence: 0.8831168831168831\n"
     ]
    }
   ],
   "source": [
    "score = len(confidence[confidence['success']==True]) / len(confidence)\n",
    "print(\"Success rate confidence: {}\".format(score))\n",
    "score = len(distance[distance['success']==True]) / len(distance)\n",
    "print(\"Success rate confidence: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence: Average time for sample: 118.47095524880194 std 282.301520229902\n",
      "Distance: Average time for sample: 6.905381865361157 std 23.686921435643317\n"
     ]
    }
   ],
   "source": [
    "meanTime = np.mean(confidence[confidence['success']==True]['time'])\n",
    "stdTime = np.std(confidence[confidence['success']==True]['time'])\n",
    "print(\"Confidence: Average time for sample: {} std {}\".format(meanTime, stdTime))\n",
    "meanTime = np.mean(distance[distance['success']==True]['time'])\n",
    "stdTime = np.std(distance[distance['success']==True]['time'])\n",
    "print(\"Distance: Average time for sample: {} std {}\".format(meanTime, stdTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
